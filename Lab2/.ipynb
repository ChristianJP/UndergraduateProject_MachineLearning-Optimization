{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP24111 - Exercise 2: News Article Classification\n",
    "\n",
    "## 1. Task description\n",
    "\n",
    "You will work on a news article classification task.\n",
    "The provided dataset includes a total of 800 articles taken from Reuters newswire.\n",
    "They belong to 4 classes: \"earn\" (1), \"crude\" (2), \"trade\" (3) and \"interest\" (4).\n",
    "There are 200 articles per class.\n",
    "Each article is characterised by word occurrences.\n",
    "The list of used words is called a vocabulary.\n",
    "In our dataset, the vocabulary includes a total of 6428 words. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preparation\n",
    "\n",
    "First we need to import the data.\n",
    "Run the below cell to load the data using NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.sparse\n",
    "\n",
    "data, labels, class_names, vocabulary = np.load(\"ReutersNews_4Classes_sparse.npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Note on Sparsity\n",
    "\n",
    "Most documents only contain a small subset of the vocabulary, resulting in a very sparse data matrix.\n",
    "To take advantage of the sparsity, in this exercise `data` is represented as a `scipy.sparse.csr_matrix`, which can store sparse matrices efficiently while still allowing efficient row-based indexing.\n",
    "You can learn more about `csr_matrix` and other ways of dealing with sparse matrices at https://docs.scipy.org/doc/scipy/reference/sparse.html.\n",
    "\n",
    "Note, however, that `data` is **not** a normal NumPy array.\n",
    "While most operations will be the same as with a normal dense array, **you cannot use a sparse matrix to index another matrix**.\n",
    "If you need to do this, either first convert the matrix to a NumPy array with the `toarray()` method, or use methods specifically designed to work with sparse matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 2)\t1\n",
      "  (0, 3)\t3\n",
      "  (0, 5)\t1\n",
      "  (0, 8)\t1\n",
      "  (0, 10)\t1\n",
      "  (0, 11)\t1\n",
      "  (0, 12)\t1\n",
      "  (0, 13)\t1\n",
      "  (0, 21)\t2\n",
      "  (0, 24)\t1\n",
      "  (0, 105)\t1\n",
      "  (0, 127)\t1\n",
      "  (0, 227)\t1\n",
      "  (0, 275)\t1\n",
      "  (0, 334)\t2\n",
      "  (0, 341)\t1\n",
      "  (0, 348)\t1\n",
      "  (0, 359)\t1\n",
      "  (0, 411)\t1\n",
      "  (0, 426)\t1\n",
      "  (0, 1428)\t1\n",
      "  (0, 2058)\t1\n",
      "  (0, 5555)\t1\n",
      "[[0 0 1 ... 0 0 0]]\n",
      "['share' 'split' 'say' 'two-for-one' 'shareholder' 'annual' 'meeting'\n",
      " 'reuter' 'ct' 'note' 'company' 'pay' 'subject' 'increase' 'stock'\n",
      " 'dividend' 'april' 'northern' 'declare' 'approval' 'telecom' 'post-split'\n",
      " 'nt']\n"
     ]
    }
   ],
   "source": [
    "print(data[41]) # Sparse, will print the non-zero indices and their values.\n",
    "print(data[41].toarray()) # Convert back to a NumPy array. Note that the result is a (1, 6428) matrix, not a vector.\n",
    "# print(vocabulary[data[41,:] > 0]) # Can't index vocabulary with a sparse matrix.\n",
    "rows, columns, values = scipy.sparse.find(data[41,:]) # Find the non-zero entries in the 42nd document.\n",
    "print(vocabulary[columns]) # Prints the words present in the 42nd document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see the full vocabulary, you can run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "island, telephone, share, split, approve, say, previously, announce, two-for-one, common, shareholder, annual, meeting, reuter, year, net, shr, loss, nil, vs, profit, ct, rev, mln, note, current, include, charge, discontinue, operation, dlr, ec, state, tax, majority, european, community, member, strong, reservation, import, domestically-produced, oil, fat, propose, commission, senior, diplomat, special, committee, agricultural, expert, voice, objection, measure, prepare, ground, farm, begin, monday, add, france, italy, indicate, support, proposal, lead, initially, tonne, 1987/88, price, round, complete, sale, french, unit, business, compagnie, francaise, group, investor, employee, minnesota, disclose, term, deal, plan, asset, electronic, shoe, town, end, jan, respectively, december, wisconsin, fwb, buy, bank, corp, acquire, bancshare, cash, acquisition, hold, company, total, billion, purchase, time, earning, office, paul, area, american, product, 3rd, qtr, period, feb, mth, avg, 4th, seven, entertainment, publication, disposal, pay, store, correct, mobil, mob, upgrade, refinery, spend, texas, catalytic, convert, component, gasoline, use, super, unleaded, allow, continuous, basis, shutdown, currently, shut, twice, produce, barrel, day, construction, start, late, completion, set, output, inc., result, slightly, ab, weakening, dollar, cause, drop, chief, executive, good, final, report, release, earlier, allocation, crown, compare, despite, fall, industrial, high, car, truck, completely, sell, year-end, operate, income, financial, strength, exceptional, opportunity, invest, future, meridian, energy, letter, intent, development, privately-held, decide, terminate, exclude, quarter, extraordinary, gain, british, minister, discuss, public, spending, finance, need, control, talk, today, chancellor, exchequer, nigel, lawson, treasury, spokesman, review, economy, domestic, decline, comment, subject, concerted, action, arise, u., currency, dip, sharply, week, month, relative, stability, agreement, major, industrialised, nation, paris, february, stabilise, feed, heller, urge, broad, reform, aid, banking, federal, reserve, board, governor, robert, strengthen, permit, formation, service, involve, like, insurance, real, estate, security, speech, delivery, new, york, analyst, association, believe, increase, diversification, line, key, idea, advocate, regulation, various, thrift, investment, subsidiary, handle, limit, place, extension, credit, associate, institution, transaction, necessary, avoid, abuse, position, require, serve, make, commitment, maintain, capital, word, fail, long, positive, commercial, enterprise, provision, flow, effect, corporation, customer, deposit, assure, incentive, remove, access, national, international, united, mean, steady, america, world, table, competitive, department, qtly, div, pct, 2-for-1, stock, cie, advance, science, datum, available, raise, dividend, quarterly, form, ask, number, payable, pre-split, april, record, distribute, receive, commonwealth, settlement, debt, stockholder, california, concern, title, northern, county, costa, san, home, saving, initial, cotton, u.s., run, season, census, bureau, brand, bp, manage, director, hike, standard, offer, user, merger, pacific, union, processing, mutually, agree, withdraw, negotiation, sign, merge, november, continue, ownership, commit, additional, history, expect, after-tax, close, primarily, direct, mail, marketing, likely, meet, growth, goal, lose, industry, regular, payout, declare, class, equal, prior, manufacturing, paper, dunn, jame, river, partly, reduce, contingent, payment, offset, closing, approval, satisfactory, labor, old, republic, int'l, june, crn, money, market, mutual, fund, expectation, value, petroleum, plc, half, signal, patch, think, bid, clear, confidence, higher, sanford, margosh, shearson, lehman, brother, early, tender, opec, win, war, crack, bruce, huge, implication, rest, issue, particularly, target, mention, usx, court, draw, attention, australian, holme, rumor, foresee, firm, takeover, situation, exception, possibly, partner, ago, restructure, point, rally, response, exxon, xon, rise, 1-1/8, chevron, chv, jump, texaco, tx, climb, 1/4, unocal, ucl, 1-3/4, occidental, amoco, 6-1/4, heavy, trading, session, wall, speculate, boost, 2-1/4, fact, giant, change, outlook, stay, hasty, view, look, long-term, heart, exceed, benchmark, crude, west, intermediate, trade, able, bright, alaskan, prudhoe, bay, field, north, extremely, attractive, large, just, fit, dean, witter, eugene, ahead, government, u.k., dispose, way, unite, revenue, cable, acre, co., finalize, bancorp, universal, holding, contract, obligation, chairman, freedom, recognize, first-quarter, defer, complex, recognition, come, repayment, loan, grant, commerce, house, dec, investigate, assurance, succeed, experience, negative, waiver, marine, midland, working, guarantee, secure, substantially, bernard, president, act, officer, engineering, halt, software, shipment, temporarily, technical, problem, program, anticipate, resume, fourth, oper, adjust, reverse, october, fair, lane, right, realty, research, backlog, cardena, decision, jorge, manager, colombia, coffee, federation, important, emerge, upcoming, organization, london, march, council, export, quota, routine, happen, unlikely, tell, journalist, suspend, failure, colombian, reporter, weekly, brazil, far, apart, prompt, yesterday, policy, know, project, stockpile, level, producer, accord, statistic, shortfall, regulatory, agency, 1st, earn, year-ago, tobacco, strike, introduce, low-priced, cigarette, performance, operating, trader, soviet, sugar, raw, night, hand, discount, spot, source, japanese, cargo, thai, relatively, nearby, remain, sharp, help, provoke, cover, cent, pound, limited, trust, date, proceed, hilton, holder, cease, liquidate, worth, debenture, substitute, distribution, connection, represent, balance, satisfy, liability, second, vote, profitable, follow, specific, figure, definitely, news, amendment, certificate, relate, center, property, plastic, work, denis, consumer, delegate, formally, present, friday, widespread, outstanding, item, reach, bilateral, consultation, delegation, main, draft, rule, package, certain, want, discussion, differential, different, origin, forward, material, minor, modification, original, intend, single, candidate, post, coast, exist, gmt, management, pledge, provide, expand, base, combustion, csp, environmental, principle, e.c, jordan, privately, pom, potomac, electric, power, virginia, territory, mainly, low, margin, cost, enter, head, design, manufacture, restructuring, adversely, affect, realize, significant, expense, remainder, pact, ohio, wholly, warrant, creditor, thing, micro, device, develop, chip, gate, complexity, harden, n.y, book, acceptance, nationally, schedule, borrowing, city, borrow, wednesday, two-week, statement, assumption, preferred, reorganization, resource, equivalent, previous, 3-for-2, effective, entitle, arsenal, determine, small, fiscal, attribute, pressure, cut, gross, addition, incur, aim, productivity, undertake, extend, hour, salary, job, save, annually, care, supply, average, free, depressed, seasonally, revise, economist, poll, forecast, forgiveness, dealer, collapse, foreign, exchange, speculation, germany, big, crash, stand, damage, claim, case, seek, mark, accuse, manipulate, private, great, recently, appeal, people, medical, evidence, life, crucial, hernandez, arturo, grisanti, regional, exporter, critical, effort, achieve, recovery, stabilize, non-opec, danger, reversal, really, movement, depend, venezuela, speak, opening, fifth, ministerial, informal, latin, caribbean, ecuador, mexico, attend, conference, observer, combat, congress, jaime, lusinchi, miraflore, presidential, palace, javi, espinosa, jose, assistant, secretary, perry, rubio, howard, b., significantly, inventory, potential, possible, shift, demand, brazilian, natural, gas, production, petrobras, basin, country, bpd, consumption, derivative, fuel, medium, general, central, three-for-two, white, semiconductor, economic, recommendation, reagan, retaliate, japan, alleged, unfair, practice, official, retaliation, curb, impose, senate, unanimously, penality, hard, hit, summer, stop, dump, open, return, anti-dumping, duty, semiconductors., indiana, plant, stake, chicago, banker, sec, try, gold, study, recommend, water, license, arrangement, appropriate, financing, estimate, feasibility, canadian, short, yield, rate, probable, ore, grade, yearly, break, zone, considerable, red, lake, mp, coal, related, nominal, consideration, specify, alberta, michael, retain, unspecified, royalty, reclamation, expire, reclaim, activity, occur, principal, authorize, proposed, article, option, broaden, multinational, sweden, variety, instead, optimistic, grow, leadership, intelligence, defense, congressional, joint, improve, worker, attitude, equipment, account, adopt, bring, apparent, solution, immediate, lack, appear, count, n't, marshall, goldman, harvard, university, hearing, fast, step, similar, peter, institute, advanced, commodity, discourage, innovation, technological, resistance, overall, surface, massive, party, complain, carry, conflict, quality, predict, technology, microprocessor, allowance, writedown, preliminary, finding, conduct, examination, authority, adjustment, deplete, environment, improvement, near, portfolio, non-performing, marathon, macmillan, ctc, ontario, ruling, uphold, block, hear, alfre, david, leave, join, motion, restate, reflect, january, delay, force, sheet, omaha, writeoff, subordinated, gatt, warn, budget, protectionism, emphasis, deficit, misplace, lie, agreeement, tariff, stress, protectionist, threaten, fundamental, size, remedie, encourage, personal, percentage, washington, resist, macroeconomic, barrier, little, reduction, inflation, basic, combination, insufficient, excessive, expansion, slow, workforce, risk, loom, imbalance, explanation, prediction, realignment, bear, sizeable, combined, impact, rapidly, worsen, climate, uncertainty, push, turn, trade., surprising, depreciation, expensive, suggest, idle, human, underutilised, factory, gear, abroad, stagnant, pattern, sector, decade, moderately, indebted, chile, philippine, south, korea, thailand, smelter, northw, mid-may, capacity, lease, corp., reopen, successful, unchanged, index, consecutive, year-on-year, september, winter, clothing, vegetable, electricity, housing, education, footwear, unadjusted, tokyo, food, utility, n.z, zealand, statistical, panel, sanction, violation, u.s.-japanese, administration, announcement, frustration, probably, consult, aide, persuade, abide, july, govern, u.s.-made, dumping, closed, unanimous, penalty, contain, semiconductor-based, television, video, cassette, recorder, nakasone, visit, prime, yasuhiro, week-long, cabinet, masaharu, gotoda, resolve, friction, venice, summit, western, democracy, tadashi, kuranari, accompany, ministry, violate, microchip, asia, australia, bp.l, compensation, subsidy, refiner, partially, enable, modest, pre-tax, pct-owned, sustain, exploration, endeavour, 33-1/3, chemical, maker, farmer, finalise, nitrogen, anz, jardine, h.k, turnover, bonus, par, august, broken, hill, pty, brkn., minority, mineral, steel, corporate, adjusted, finish, machine, tape, machinery, downturn, planning, gnp, match, balanced, four-for-one, ordinary, quote, simon, section, especially, hong, kong, land, fleming, lower, reorganisation, strain, flexibility, recent, pende, exercise, nearly, transfer, hk, strategic, spin, dairy, plus, cross, transform, middle, east, weakness, strategy, structure, policy., create, midday, rumour, 1985/86, range, register, qualify, tax-free, introduction, imputation, rank, influence, legislation, confine, division, generally, volume, bass, strait, operational, difficulty, largely, iron, southern, cement, acreage, surplus, lobby, agriculture, usda, taiwan, fulfil, protest, award, dominican, taiwanese, list, badly, lay, staff, entire, container, ship, cancel, local, press, later, file, protection, law, china, morning, charle, comprise, singapore, manila, seoul, osaka, provisional, survey, 1986/87, certainly, long-standing, reason, peso, ready, throw, submit, corazon, aquino, wait, election, enjoy, drive, longer, region, learn, mistake, diversify, corn, farming, cloth, lesson, diversified, industry., room, renewal, write, revive, subsidise, markets., uneconomical, bullish, artificial, happy, supplier, restore, watch, slash, suit, danish, cooperative, yen, anger, telecom, dispute, equity, telecommunication, legal, telecommunications, send, postal, malcolm, baldrige, object, participation, express, oppose, role, dampen, opposition, compete, monopoly, wireless, cawl.l, ford, motor, citibank, na, cci, digital, communication, merrill, lynch, mer, competitor, reject, argue, precedent, channel, dilute, eventually, bache, political, leverage, wo, diplomatic, reasonable, sort, watanabe, keidanren, arrange, outline, thursday, newspaper, britain, apply, placement, participate, wake, spark, herald, subsequent, one-for-four, radio, station, belgian, parent, metal, link, appreciation, defence, document, defend, itself, stg, pretax, u.k, england, shortage, factor, liquidity, mature, drain, aluminium, smelt, past, cheap, primary, indonesia, calendar, tight, recover, weak, dominate, segment, passenger, light, vehicle, suffer, profitability, erode, lift, penetration, buyer, netherland, ban, suspect, foot, mouth, daniel, notify, km, northeast, province, immediately, milk, beef, alternative, canada, al, swap, deputy, jeremy, davis, broadly, nz, overseas, closer, relation, treaty, accept, normally, invite, consolidated, attributable, franc, priority, ag, anticipated, mass, dieter, satisfied, 1984/85, projection, employ, barber, conable, sake, contribution, businessman, academic, support., assist, road, bridge, infrastructure, advantage, rechannelle, notably, india, faster, developed, concessionary, lending, affiliate, ida, reconstruction, ibrd, structural, competition, maybe, und, refine, concentrate, core, five-year, convertible, redeemable, spain, assistance, daily, oblige, borrower, window, normal, overnight, suspension, 10-day, accounting, requirement, peseta, hard-pressed, soothe, defuse, mount, chance, success, slim, box, powerful, ronald, congressman, coincide, retaliatory, live, arm, separate, pep, sagge, short-term, redirect, away, over-dependence, infighting, rob, punch, prevent, insist, pass, parliament, fear, tacit, admission, inadequate, hope, quick, passage, trip, shatter, parliamentary, boycott, face, possibility, virtually, empty-handed, order, liberal, democratic, ldp, deregulation, benefit, accelerate, portion, democrat-controlled, complement, longer-term, high-ranking, advisory, body, haruo, maekawa, concrete, follow-up, potentially, politically, explosive, explicit, reality, subcommittee, consider, undergo, amounte, gradual, outright, band, 9-13/16, intervene, dealing, intervention, aggressive, selling, ease, bundesbank, touch, test, fairly, contrast, progressive, launch, supermarket, minimum, one-for-one, debate, lately, buying, programme, highlight, worldwide, destination, turkey, libya, worthwhile, enquiry, proportion, operator, tighten, considerably, eastern, react, upwards, physical, interim, pakistan, shortly, originally, tomorrow, egypt, arrival, greece, internal, sa, mining, sum, elaborate, societe, countertrade, gap, search, non-communist, conserve, wheat, tea, jute, impetus, stc, mmtc, respect, bulk, promote, indian, spokeswoman, targette, bloc, non-convertible, rupee, textile, narrow, insignificant, shrink, dynamism, discreetly, officially, bartering, yugoslavia, rail, global, clause, preference, kind, flexible, quietly, interested, aircraft, drill, rig, railway, illustrate, korean, drilling, platform, state-run, wholesale, 2nd, carryforward, wage, one-third, transportation, responsible, fish, drug, apparel, spring, merchandise, man, mmb, weather, disrupt, sea, shipping, saturday, rain, wind, tonight, frequent, southwest, northwest, wave, build, diminish, weekend, suez, lloyd, port, chamber, monthly, expected, german, so-called, grey, illegal, pose, hedge, dollar-denominated, third-party, centre, swiftly, mohamme, keen, contentious, concession, question, prove, assign, soon, fully, advise, yr, closely, st., mortgage, servicing, combine, origination, afternoon, austria, austrian, deny, suggestion, vienna, creditanstalt, girozentrale, aware, purely, purpose, han, obtain, application, process, procedure, facility, equally, non-recurring, revaluation, offering, restaurant, manhattan, headquarters, sept, distributor, manufacturer, family, trend, fee, analyze, double, dougla, moderate, particular, vice, identify, it., focus, broadcasting, electrical, consistently, poor, w., establish, expenditure, fine, smoke, condition, quickly, uk, revoke, licence, select, progress, ca, yes, cross-section, influential, increasingly, impatient, sense, urgency, undermine, margaret, thatcher, hesitate, reciprocal, clearly, mind, defict, coordinate, restrictive, feeling, inside, parliamentarian, conservative, refuse, authorise, london-based, legally-binding, channon, engage, collective, alan, clark, interview, certification, overnight., reciprocity, regard, visible, dominant, aspect, fairness., minimise, indication, weigh, wide, retail, building, course, prospect, temporary, indirectly, repurchase, 6-1/8, sydney, ltd., appliance, retroactively, capitalize, intangible, ability, ongoing, waste, removal, mar, outlet, promotional, information, des, nec, pricing, jerome, cornerstone, qtrly, contingency, drawing, fixed, zero, malaysian, malaysia, conclude, unable, implement, organize, assess, sun, publishing, publish, lewis, glamis, glgvf, rebound, florida, mile, offshore, louisiana, gulf, discovery, depth, sand, cubic, choke, owner, venture, oklahoma, slap, receiver, laser-printer, penalize, hitachi, toshiba, fujitsu, reaan, invoke, negotiator, extensive, avail, peg, intention, tuesday, spur, belief, repeat, switch, cargill, echo, warehouse, pick, tab, storage, stipulate, mandatory, disagree, lot, 'll, outside, walter, brown, verify, gather, caution, opinion, difference, pretty, plaza, travel, gro, francisco, 109-billion, rat, lawsuit, dilson, funaro, monetary, imf, carefully, space, post-split, soft, type, slump, tie, network, bond, imperial, tangible, pace, constructive, steam, pronounced, william, reynold, upward, volatile, picture, competitiveness, willing, tolerate, s.g, warburg, door, conclusion, reaffirm, n.a., pursue, adviser, instruct, grain, status, satellite, choose, battle, team, dutch, philip, sit, ally, df, 13-1/2, amid, chinese, engineer, underway, slide, scale, premium, fix, nigeria, weight, minstar, confirm, restrict, maximum, welcome, conform, ring, exclusively, dollar-based, conversion, sterling, alleviate, romania, attract, active, zinc, replace, difficult, totally, disappear, feature, volatility, presently, squeeze, deliver, widen, declaration, 25th, narrowly, notice, resident, charter, glass, dynamic, michigan, den, stage, liquid, seasonal, premi, relax, relaxation, surge, framework, emergency, professor, bit, liberalisation, end-february, angrily, allegedly, eiaj, shoichi, saba, premature, irrational, attempt, assessment, comply, agreement., governmental, reconsider, evaluate, objective, emotional, bias, heated, cut-price, american-made, salvage, multi-lateral, organisation, regret, tree, licensing, bulletin, arab, establishment, preserve, civil, devastate, productive, acceptable, meantime, protect, health, accession, postpone, scrap, abolish, evolution, foreigner, widely, wang, trouble, suitable, unacceptable, sound, conciliatory, bitter, row, explain, stance, thoroughly, kyodo, high-level, settle, formal, request, deadline, u.s./japan, investigation, asian, hammer, distinctly, hajime, tamura, miti, downplay, significance, remark, message, urgently, admit, geneva-based, police, legality, wishful, thinking, confident, unregulated, dry, acknowledge, ensure, tsba.t, likewise, islamic, idb, porfolio, redeem, emirate, wam, cooperation, gcc, bahrain, kuwait, oman, qatar, saudi, arabia, uae, restrain, mid-1986, boom, recession, fresh, coordination, quite, substantial, series, examine, kuwaiti, dinar, trade-weighted, theory, foster, stable, instrument, recognise, hamper, premier, three-year, vice-chairman, banque, morgan, guaranty, treasurer, bad, plunge, economically, brief, pave, soar, dictate, erupt, full-scale, adverse, relationship, isolate, fall-out, sure, perception, respond, that., spread, depict, severe, warning, belligerent, angry, walk, secret, draconian, enforce, irrational., meaningless., solve, convince, allegation, fuer, gemeinwirtschaft, bkfg.f, prospectus, turbulence, troubled, depress, compensate, emphasise, necessarily, debtor, deutsche, sumita, satoshi, beginning, careful, judgement, septemb, steep, stem, peru, garcia, jungle, ecuadorean, border, site, treatment, extract, u.s.-japan, refer, spare, sides., understand, all., observe, adhere, avert, hop, tone, auto, ignore, bidding, partnership, afg, reiterate, negotiate, conglomerate, fetch, inform, explore, prefer, green, correspond, george, cumulative, tropical, woolworth, indonesian, suharto, backdrop, devalue, rupiah, editorial, jakarta, deregulate, non-oil, steadily, burden, end-investor, cautious, coupon, 10-year, favourably, chain, effect., allege, defiance, non-u., chipmaker, non-regulated, 'm, nick, edward, matsushita, rapid, levy, length, erosion, tom, murtha, capel, altogether, harm, approach, contradiction, hurt, vast, carole, ryavec, salomon, stimulate, export-dependent, economy., luxembourg, deterioration, weaken, deteriorate, provisionally, circumstance, beneficial, moment, unusual, petrochemical, regime, newly, valid, frequently, envisage, 91-day, traditional, afford, allot, differ, underlie, guilde, image, shop, inflow, behalf, easy, comparison, supplement, calculation, cartel, ail, transport, yard, capable, renew, 1988/89, sluggish, favourable, taxation, excess, allocate, guideline, fight, hostile, packaging, swedish, mel, attach, hectare, sixth, healthy, monitor, contemplate, broker, auction, est, client, tour, pioneer, popularity, popular, clearing, sight, threat, lessen, external, commissioner, stabilisation, benefitte, initiative, prepared, modestly, john, organic, maintenance, hotel, end-1986, indirect, sach, berlin, commerzbank, cbkg.f, state-owned, bonn, high-technology, reliance, broadly-based, divide, exciting, method, barclay, independent, subscribe, continued, listing, retire, appoint, refrain, directly, seller, aggressively, grangemouth, explosion, accident, kill, person, hydrocracker, overhaul, african, kenya, flat, interbank, mechanism, chocolate, overhang, pull, doubt, rely, reaction, tool, manoeuvre, perfectly, sensitive, winner, effectively, scheme, sdr, disappoint, nv, surprise, apparently, favour, tate, await, organise, willingness, manner, colorado, coastal, repay, continental, motivate, 7-1/2, million, clarify, actively, gilt, gradually, three-month, fluctuate, bullishness, triton, consist, exploratory, conventional, miller, yugoslav, fso, fluctuation, calculate, belgrade, all-time, cite, automotive, injection, gm, peak, gdp, straight, wood, automobile, custom, texa, windfall, scientific, santa, mexican, petroleos, mexicano, pemex, auditor, arthur, andersen, qualified, subsequently, unisy, uis, newport, geneva, switzerland, pro, element, posted, sulphur, 6-3/8, bow, secondary, principally, seaman, calgary, montreal, mid-april, 're, criterion, formula, master, unitholder, brokerage, divestiture, bob, consistent, non-binding, seattle, contravene, event, highly, incident, reveal, remote, sufficient, outcome, dialogue, matter, agenda, representative, imagine, scheduled, blame, rica, damaging, solidarity, adoption, jopling, portugal, weighted, year-earlier, contribute, pipe, spotlight, congres, rap, enormous, symbol, crisis, symbolize, challenge, nuture, multitude, leader, byrd, democrat, speaker, jim, wright, wide-ranging, readie, dismay, sophisticated, host, citrus, tough, relief, controversial, rep., richard, gephardt, aspirant, missouri, example, mid-1988, tired, 'we, marketplace.', argument, refining, garment, maturity, definitive, merchant, lend, undeveloped, clayton, bt, itt, weakened, improved, netback, mediterranean, pipeline, sweet, sour, alaska, europe, brent, bonny, dubai, cif, iran, cruzado, devaluation, unclear, owe, permanently, golden, don, hughe, hug, execute, detroit, versus, perform, repair, athen, aggregate, silver, king, additionally, dalla, mr, fashion, f.w, roughly, processor, self-imposed, cereal, j.p, belgium, affair, scandal, approximately, jpm, mayfair, hanover, guard, park, alarm, houston, 2-1/2, advisor, heat, decrease, heating, gallon, unemployment, social, usual, arrive, correspondent, gerhard, stoltenberg, karl, otto, poehl, italian, blow, baker, meaningful, 2.0-2.5, repo, permanent, float, translate, patent, disposition, dominion, burlington, n.a, concerned, michel, query, publicly, thoma, unavailable, repeatedly, topic, consume, interesting, essentially, evening, medium-, setback, euromarket, furniture, restriction, sir, lengthy, disadvantage, montedison, spa, agro-industrial, characterize, renato, italiana, interstate, donald, entity, 4-7/8, true, story, play, heavily, fabric, outlay, johnson, enhance, unsuccessful, 5/8, last-ditch, makoto, kuroda, smith, smart, audio, likelihood, monitoring, honor, enforcement, injure, enact, counter, redress, inaccurate, supply-demand, carolina, mellon, marlin, fitzwater, spite, jone, terminal, rent, freddie, beer, guilder, spanish, el, s.a., van, africa, essential, nigerian, successfully, banana, finally, bar, moscow, 12-1/2, samuel, traditionally, shelf, aegean, armed, confrontation, ambassador, nazmi, akiman, greek, reply, turkish, content, reinvest, laser, regulator, criticize, dilution, safety, virtual, responsive, vary, installation, itc, momentum, attain, tranzonic, tnz, iii, atlantic, connect, earthquake, 90-day, iraqi, troop, iranian, iraq, occupy, command, victory, thrust, attack, warplane, tank, baghdad, plane, destroy, raid, shoot, naval, sink, boat, inspection, inspect, administrator, phase, disruption, pilot, airline, assume, realistic, vulnerable, rental, emphasize, escalate, kick, louis, tailor, irna, gholamreza, aqazadeh, manpower, training, exploitation, forum, consequently, slowly, generalize, discipline, restraint, imposition, tend, proved, wilson, stimulus, more., discover, stick, definition, dl, inclusion, one-time, copper, vice-president, consortium, hopeful, cp, historically, streamline, jeffrey, allen, preparation, costly, air, fare, lender, classify, nat'l, spirit, ccc, importer, usa, exclusive, duty-free, locate, wine, compliance, wojnilower, boston, albert, subvert, occasion, harder, justifiably, seriously, participant, hiccup, dress, end-of-fiscal-year, above-average, pick-up, unsustainable, ray, pratt, version, stewart, southeast, fertilizer, exposure, somewhat, ratio, leaseback, distance, strongly, card, nova, scotia, 12-month, survival, bancorporation, implementation, existence, dependent, trim, buoy, magnitude, stanley, volcker, downward, remedy, chase, industrialize, testimony, answer, persistent, worry, ceiling, extent, floor, breakdown, inability, chesebrough, chesebrough-pond, unilever, favorable, said., envision, slight, santo, onshore, oilfield, cast, end-1987, rio, cra, claus, koehler, speculative, separately, hiss, background, dash, let, sentiment, accommodative, surrey, regardless, diametrically, activity., monetarist, concretely, counterpoint, overly, reuter^m, journal, debit, complaint, withdrawal, unless, liquified, rationalisation, swiss, shanghai, ta, hua, modernise, domestically, catch, riyal, spot-next, spill, 6-3/16, 5-15/16, 7/8, edge, 6-3/4, suisse, confirmation, exempt, read, page, grace, disburse, utilisation, household, seventh, socialist, campaign, sunday, privatisation, director-general, la, sweeping, paribas, et, lombard, eliminate, algeria, erasable, programmable, memory, unfairly, proof, justified, subscription, basically, urgent, postwar, criticism, meeting., notable, annuity, hague, goodwill, g-7, appreciate, suppose, holiday, warmer, guidance, entry, presence, gelco, kingdom, pool, realise, district, bargaining, membership, suntrust, sti, argentine, cow, default, r., c., kansa, waive, boveri, bbc, bbcz.z, carlo, e.f, hutton, banco, 7-3/4, inject, category, mixed, slowdown, semi-annual, disappointment, cope, rout, sustained, wealthy, poorest, occasion., graphic, fhlbb, two-third, depository, adequate, consent, plc., restricted, esso, educational, sallie, mae, student, 5-14, mac, frankfurt, upper, unnamed, interior, omit, exchangeable, resign, s., t., leasing, demonstrate, growth., standstill, diamond, salt, incorporate, states., presentation, reference, briefly, canron, quebec, rotterdam, undercut, upturn, strictly, already., bethlehem, inland, efficient, turnaround, mid, 1/8, neutral, mix, diagnostic, pharmaceutical, hot, unlike, brasil, cacex, orderly, sustainable, policy-making, simply, compensatory, royal, roy, jersey, joseph, undervalue, months., rome, contact, retirement, notion, semiannual, so., mid-1990, game, cruz, accordance, instruction, obvious, drexel, lambert, burnham, accomplishment, comparable, kenneth, puerto, rico, liberty, citicorp, entirely, t-bill, bidder, consensus, informally, resolution, ctyn, rd, dutch/shell, fb, quantity, jeopardize, belong, involvement, counter-productive, brighten, greenshield, toronto, slip, curtail, ussr, juice, freeze, degree, amend, trigger, shp, beverage, shamrock, 20-year, evaluation, 1-1/2, adam, detailed, argentina, foremost, bankruptcy, trap, provincial, newhall, dependency, inevitable, disincentive, synthetic, foodstuff, receipt, conjunction, facilitate, dd, tract, conoco, hydrocarbon, patient, write-off, funding, direction, mcdonnell, strict, inch, extended, miss, minus, correction, tucker, address, mandate, worst, uplift, overcome, precision, jack, identity, chicken, favor, calling, medicine, fort, determination, agreed, hefty, wish, technique, tackle, tactic, unreasonable, stripper, arctic, wildlife, refuge, judge, illegally, jay, irve, dismiss, ottawa, edmonton, lukman, couple, annum, rilwanu, industrialise, swing, stimulation, inappropriate, helmut, kohl, severely, stretch, revision, die, condemn, speed, century, adherence, hint, modify, recoverable, one-fifth, endanger, caribou, lee, superior, ncnb, maryland, rejection, maximize, turmoil, false, misleading, richfield, arc, mold, shultz, selective, confront, impossible, reasonably, bold, champion, breach, punta, del, este, auspex, jamaican, resort, chair, jamaica, senegal, papua, guinea, coat, bcf, mideast, vital, military, mountain, camp, actual, logic, aspen, individual, dan, timing, undetermined, mercantile, hardware, metric, feel, interprovincial, shall, hr, norwegian, brass, burst, thousand, metre, shell, vessel, friendly, tanker, fly, task, planned, municipal, language, telegraph, andrew, inroad, continuation, mfn, one-year, hungary, fate, missile, republican, imply, enhancement, g., expanded, massachusett, modern, optimism, analysis, sam, veto, destine, legislator, enactment, persian, supporter, critic, bombing, leftist, army, ecopetrol, estimated, pump, columbian, recipient, hide, promising, constraint, liberalize, lifting, protected, surround, venezuelan, manuel, azpurua, one-half, norway, senator, appropriation, iran-iraq, contrary, furthermore, choice, mitigate, jawboning, barney, harris, upham, upside, westpac, indicator, anza., crane, shot, austerity, disaster, anxious, divert, usually, disagreement, budgetary, useful, colleague, unusually, promise, rice, 1990s, viability, intensify, overcapacity, variable, rupture, guillermo, dehesa, spell, drastic, plenty, gill, acid, unilateral, denman, multilaterally, dangerous, path, impede, six-month, pittsburgh, rush, shield, looming, scope, obstacle, abolition, coalition, swell, copy, lay-off, struggle, generate, autumn, cftc, abandon, unresolved, bro, comprehensive, satisfactorily, cepe, plain, petrocanada, fran, permission, ample, merely, arizona, code, future., high-tech, crossroad, destocke, boee, hydraulic, medium-term, mission, cd, york-based, forma, restart, south-east, two-day, tourist, regain, fadhil, al-chalabi, sacrifice, credibility, caraca, painful, conservation, easily, reflection, rebuild, buoyant, unveil, align, insure, self-sufficiency, embassy, intense, risky, audience, dismantling, dismantle, ireland, refusal, narrowing, inevitably, export-led, hongkong, overdraft, s.korea, won, condensate, marginal, excise, 5.5p, gauge, taxpayer, voluntary, telex, guide, pertamina, contractual, understanding, commencement, crush, reschedule, hardship, desire, upwardly, norman, der, alter, severance, frank, westminster, nwbl.l, rpt, intact, unwilling, fence, mildly, pessimistic, negotiable, presidency, unity, package., oil-rich, gasoline-rich, first-half, mirror, minimal, one-quarter, barter, reluctance, kleinwort, cts/bbl, novemb, calm, nervous, subsidize, posting, phillip, wti, spin-off, disappointing, bernstein, multiple, shc, edmonton/swann, bbl, imo.a, tultex, ttx, margarine, hugely, southland, dlrs/bbl, murphy, permian, slc, citgo, age, wildcat, petro-canada, antwerp, firmly, justify, discriminatory, unp, champlin, nippon, strip, deductible, eventual, two-year, initiate, powdered, hemisphere, dupont, tran, criticise, uruguay, procurement, oversee, api, temper, benson, availability, lubricant, unprofitable, efficiency, inspire, indefinite, integral, embark, servant, toll, wrong, effectiveness, film, contractor, lucrative, wyome, airport, fruit, worse, sorely, ryan, la., moore, closure, accumulate, lag, steve, prevail, dwindle, english, player, rich, dozen, majeure, sulphuric, stoppage, hale, railroad, thought, husky, substance, hyo.to, wedge, u.s.-canada, u.s.-canadian, brian, mulroney, oecd, halve, marked, finland, fsi, nfsi, reeacquisition, precambrian, uneconomic, grease, monkey, gmhc, nov, acpt, mnst, respective, toog, option-granting, asc, kasler, kasl, un.a, angus, cbm.n, niall, fitzgerald, divergence, 50.17p, stauffer, lipton, surf, detergent, peke, discard, prejudice, generalise, gsp, print, counsellor, chen, shibiao, behaviour, out-of-date, pickup, insititute, accountant, intek, idcc, population, pharmacia, phab, st, once-off, know-how, adr, parity, lkb-produkter, intermedics-intraocular, dbkg.f, bankamerica, clash, minute, fre, trademark, agent, post-tax, op, dane, elimination, bank/canada, uncertain, guinean, lifetime, healthcare, herman, croo, re-orient, europe., introducte, problems., products., stupid, upset, mosty, suprlus, diverted, clout, fom, west., atmosphere, dramatize, headline, rostenkowski, temptation, club, d-ill., screen, plea, fairness, 1/2, fellow, stephen, career, ecgd, aged, convern, lump, at., trough, qustion, newsletter, sesame, artificially, catastrophe, evident, reluctant, luncheon, suicide, airbus, industrie, unexpected, midafternoon, unique, reshape, ccr, harold, annualize, carryover, ultimately, standpoint, certainty, timely, 30-35, saudis, jawbone, longshot, cheating, appearance, mckinley, oversell, rally., yeterray, indidate, denial, postition, subroto, canot, marion, indepedent, slack, 4-1/2, panic, sooner, jam, raymond, pancanadian, whitehall, distillate, residual, francisco-based, sponsor, patrick, leahy, d-vt., sen., melcher, d-mont., donation, pl480, concessional, bangladesh, tunisia, morocco, injury, apple, yr-ago, wellemeyer, ope, interfuel, resolved., exemption, mcdonald, non-voting, problem., pontiac, 24-month, 36-month, 48-mopnth, 60-month, equip, interst, ann, camco, specifically, ought, infe, apolonio, ruiz, ligero, four-year, fad, context, abroad., swift, korean/taiwan, fairchild, lastly, market., treat, bind, fourteen, 13-week, brown-forman, bfdb, refund, transition, soften, easing, compatible, hugo, paeman, multilateral, etienne, davignon, luyten, energy/california, curti, birr, bolster, munger, track, dreg, ed, malmgreen, marker, blend, stripp, extraction, cloud, kern, crawl, mitchell, guerard, srd, deep, gathering, simple, sudden, idaho, unfortunate, gat, woong-bae, rha, sources., parts., federally, u.s.-, briefing, low-price, 12-nation, preferential, minoru, endo, unfounded, herring, prohibit, unprocessed, salmon, herre, stiff, 3-1/2, algerian, counterpart, belkacem, nabi, ap, permament, alick, buchanan-smith, diving, buchanan, snith, brent-grade, style, britian, oil-consuming, oil-producing, hal, february., nugent, oilpatch, lawmaker, revitalize, tertiary, coherent, way., deplore, shy, fertiliser, syndicate, six-year, seven-year, mhc, dlr/bbl, wrap, cap, drag, u.s.protectionism, eec, retaliate., ec-u.s., u.s.-ec, brink, reesentment, unilaterally, deadlines., commuity, better., bypass, agreeeement, arbiter, interpret, wonder, 49-1/8, accomplish, load, financier, route, yeutter, carlos, drawdown, preparatory, petrleum, strive, faith, short-covering, quiet, dead, unbalanced, limitation, balance., honour, diversity, ht, bko, ike, kerridge, belgolux, belgo-luxembourg, bleu, half-point, broad-based, 12-member, kaputin, privileged, beneficiary, kina, exactly, undersecretary, wallis, domestic-led, supercomputer, kansai, jeopardy, fundamentally, labour, heighten, chartered, polish, poland, precise, hypothetical, blur, illusory, excuse, under-, achieving, favoured, suppression, martial, devise, offshoot, envoy, extrapolate, freely, theoretical, evaluation., illusion, misunderstanding, phenomenon, nebulous, curbing, janusz, kaczurba, pap, uncommonly, dlrs., moral, torpedoing, ice, pole, immorally, solidarity., wladyslaw, baka, partners., debt., obstruct, superpower, cooperate, anatolian, egyptian, overproduction, arabian, overprice, country-by-country, gabon, decree, gazette, interest., mike, ocean, warwick, leed, dresdner, exit, amstutz, underestimate, detect., proceeding, administer, newsprint, greatly, carroll, proportionately, georgia, rip, archer, taper, gnt, independently, prestige, financially, wilderness, premdor, ho, peninsula, staley, coke, cpl, desjardin, visa, confederation, caisses, populaires, d'economie, desjardins, unpaid, billing, designate, petroleo, pdvsa, doe, herrington, better, tap, neighbour, dollar/yen, urging, diet, populous, ratification, unofficial, safe, forbid, crumble, cautiously, absorb, craa., a/, dependence, li, petition, prospective, ferdinand, marco, now., relieve, pall, 8-1/2, mediator, picken, accrue, importance, firming, quake, pile, paralyse, society, perceive, tarrif, equatorial, equa, casey, dia, unpleasant, demonstration, occurrence, felipe, gonzalez, maximium, companion, anticipation, nice, revalue, gesture, backing, hypothesis, jurisdiction, understandably, dennis, eradicate, inhibit, legitimate, opecna, secretariat, price., biannual, noticeably, month., lifter, entail, extraordinrary, matrix, seven-state, assertion, entrant, fortune, constant, cook, carlucci, mthly, sc, pre-budget, penal, 11-3/4, drew, three-quarters, rates., 1.5798/808, 1.5650/60, 2.8900/60, 2.8720/50, re-rating, fellner, bout, bet, upheaval, harmful, pause, guess, egpc, ras, bahar, stockbroker, prudential, ward, buildup, inflate, striking, almir, fault, harbour, kit, tandem, yellow, 3/8, hurdle, 3-3/4, underproduce, correct., propuce, 75-100, refiner-buyer, free-for-all, seven-nation, twice-postponed, grades., fibre, mississippi, pearl, encounter, u.s.-european, harmony, bailey, attendance, tension, jean-claude, paye, franz-josef, feiter, heed, differentiate, disparity, profit-taking, suport, bouy, depression, rescheduling, simmon, phil, icg, compose, noir, yugoslavian, egon, padovan, wmx, safeguard, purusant, internationally, douglas, anybody, marketplace, ankara, yalim, eralp, territorial, berne, iea, cutback, norbec, leeway, 0.1-0.2, 0.2-0.3, yanbu, ngl, centrally, non-conventional, tar, processie, curtailment, refinancing, isthmus, maya, axp, incline, pbt, welfare, stone, sto, ^m, allowable, g-6, culminate, start., steward, ominous, society., illinois, evan, indefinitely, pumping, corporacion, estatal, petrolera, ecuatoriana, tremor, salado, aguarico, reventador, volcano, epicentre, seismologist, 12-point, mercalli, ecaudor, property-casualty, bush, imediately, temperton, 72-73, cox, ebc, amro, one-week, hoare, govett, run-up, glory, ian, harwood, mercury, confound, excitement, 3/4, pertain, three-months, sovereign, writer, kilometer, comparative, shake, greet, jacobson, destocking, ultimate, indefintiely, short-haul, scarce, readily, skeptic, hanke, friedburg, quotas., government-to-government, resold, anniversary, repeal, out-of-pocket, lumber, random, eve, assert, persaude, collision, pete, 7-1/8, stumble, beaufort, hinder, vacuum, algier, deploy, stablise, prices., petro-chemical, fishery, coradian, cdin, nicaragua, paraguay, intended, saskatchewan, flow-through, notification, u.n, m., glut, override, interpretation, re-export, apartheid, rationale, 24-hour, seven-day, one-month, two-month, three-, nine-months, 3-1/4, savings, fade, medium-sized, deck, consultative, iraq-turkey, landslide, adana, hurriyet, kirkuk, yumurtalik, alert, lago, agrio, balao, hook, eighth, hector, hurtado, unwillingness, sideways, 100-1/4, 5-3/4, 99-3/4, increased., fixed-rate, kassenobligation, fob, submission, taka, proper, discounted, nioc, colder, disguised, vlcc, individually, obligate, impair, whichever, advantageous, sell-out, woe, showdown, bipartisan, sept., grip, parking, contel, tumaco, desirable, lasting, japan., world-wide, anti-inflation, breakthrough, breathing, export-import, p., roxy, shape, chl, jwc, generous, loss-making, froze, abdelaziz, adequately, 2-3/4, roger, planner, throughput, have., roberto, fendt, govt, exact, deem, 6-1/2, untied, seminar, oil-dependent, expatriate, spate, doha, staunch, penalise, terribly, wealth, vat, one-for-two, fruitful, denomination, bolivar, mid-june, stopover, 9-1/2, 5-1/2, overshoot, sheikh, bin, sultan, tendency, irish, eagle, willy, clercq, mee, cyprus-based, authoritative, oil., entitlement, pan, ditch, mitsuru, uchida, waseda, memorandum, expiry, endorse, testing, outer, inherent, practical, range., scottish, flatten, transact, four-day, exports., reading, seperate, north-central, guerrilla, three-day, economical, joe, emergence, truly, boiler, stream, yukio, interchange, fledgling, depletion, violent, 50-minute, dramatic, dresser, di, ali, schlesinger, liberalise, 1980s, exploit, al-rai, al-aam, exert, genuine, nervousness, theirs, 13-member, fahd, doldrum, justification, wil, aramco, ex-partner, rearrange, piw, prince, porex, medco, containment, added., maxwell, iit, norske, stat, oljeselskap, stat.ol, statoil, haltenbanken, colony, voluntarily, peerless, softwood, countervail, bomb, quinn, dallas-based, comeback, ineffective, annoy, deserve, fulfill, 6-7/8, saddle, 1973-74, embargo, parish, displace, insistence, offical, facto, retroactive, market-related, tranche, 1987-92, oda, 28-day, 6.5p, sufficiently, ebullient, reputation, bloated, 1960s, finger, markka, 27.5p, peasant, peking, accusation, summon, suleiman, al-sabah, hisham, nazer, riyadh, architect, distortion, deeply, basix, bas, cultural, unjustified, deflect, realism, petronas, spoil, prosperity, advice, deflationary, fan, countenance, stability., abdul, rachman, ramly, 9-1/4, plough, 7-1/4, schlumberger, slb, rid, mmc, disturb, subdue, blip, encouraging, opec-led, srv, third-quarter, lasmo, billlion, trillium, transamerica, drummond, oilman, upsurge, speedy, armor, bilion, unnecessary, lpg, successor, minimize, perez, kharg, toy, coeur, d'alene, deduction, praise, issuer, bk, height, trace, pat, carney, distort, canadian-u.s., flaw, lunch, shut-in, potash, vow, downstream, corpus, christi, depositor, 20s, abundance, eager, foolish, foolishness., doing., testified, rack, amazing, japanese-made, 14th, traveler, nov., 30-year, corresponding, ivaco, 1-1/4, year., indebtedness, smooth, non-manufacturing, vice-foreign, zhou, nan, six-monthly, rotating, topple, fatal, unpopular, nakasone., flare, faction, today., ammunition, rei, shiratori, smoulder, nail, coffin, grave, hutchison, whampoa, discriminate, impatience, mede, akzo, akzo.as, signing, predatory, hit.t, kilobit, dram, oki, amortisation, compound, delicate, pain, cheung, sq, aims., ammonia, electromagnetic, categorically, rhetoric, terra, unabated, beyond., inflation., semiconducter, saver, kentucky, cntr, pearson, trustco, ceremony, welcoming, government-owned, verge, avery, escape, mlc, elk, sympathetic, discharge, elgin, captive, beneath, getty, nymex, shrug, underpin, hartford, quarter-point, mcculley, 26/27, aubrey, lanston, fomc, liro, pass., elizabeth, reiner, line., foreseeable, non-strategic, policymaker, industrialisation, viewpoint, debt-equity, six-member, g.c, goh, 5-1/16, 4-13/16, re-invest, tata, setter, bombay, enthusiastic, macsharry, punt, kearney, peop, fortnightly, engagement, 30-69, 30-124, 70-88, 125-150, 89-123, 151-173, 124-150, 174-182, 151-349, 183-349, 350-360, mtrc, von, cil, prescribed, 62-3/4, 83-1/8, 54-7/8, opertation, fos, capcity, mlotok, bunch, shaken, rough, fluctuating, post-budget, prt, henceforth, oil-related, prt-exempt, reallocation, tidy, incorrectly, ammendment, gareth, lewi, davy, mackenzie, edinburgh, osprey, arbroath, reward, bootle, safety-first, 9-11/16, simmond, electorate, tomrorow, one-point, analyse, small-print, 10-1/2, gel, pln, house-ordered, imports., pdvsa-champlin, eventuality, maturation, adapingthe, hydro-treating, difficultiesand, 80-85, ahme, wainco, wol, grandmarais, prspect, jefferson, frion, tweedel, perforation, untested, fhl, oapec, al-wattari, /oapec/opec, optimal, unviable, high-cost, full-fledged, euro-arab, allotment, anita, sar, venezuela-ecuador, fernando, alvite, remit, quito, creation, non-north, community/oapec/opec, geography, antonio, domenici, flawed, firstcorp, fcr, leather, reinveste, top-level, peaceful, al-khalifa, 13-nation, al-anba, less., opt, baht, mismatch, 10-3/8, lowering, mid-1987, dlrs/barrel, tapi, tradeable, aomi, mayor, roel, dunnen, twinned-port, drsd.f, longer-dated, routinely, hiring, platinum, rebel, handy, harman, pson.l, spr, oesterreichische, mood, saint, area., customarily, recording, well., gatt-approved, counter-reaction, threshhold, textile-state, review., bus, 20-month, neyra, earnng, coinage, nation-wide, profile, distinction, saf, essf.pa, sur, 1985-86, emhart, emh, chiefly, wrought, cenergy, crg, canterra, scotian, east-southeast, halifax, meter, lacey, mcentee, mcginley, karnosky, materialize, widerange, weave, florio, counterfeit, copyright, subversion, customs-cleared, yen/dollar, homeland, shiv, shanker, herbal, usher, balancing, newly-established, ke, stamp, new-found, underline, watchword, recklessness, dominance, explicitly, abdulaziz, al-salim, breakneck, tale, legendary, unpunished, outsized, non-tariff, octoer, high-yield, insured, surcharge, saudia, state-oil, 40-mln, micron, conviction, clear-cut, dampened, retracement, refco, connery, afterwhich, leiner, kahan, sizable, recur, automatically, pechiney, protocol, gosagroprom, vsevolod, murakhovsky, visnew, ahmed, zaki, yamani, scheduled., 13-year, over-production, measures., assemble, thrash, tihamah, abal-khail, oil-based, long-delayed, based., shipping-to-hotel, redec, fighter, taipei, lloy.l, resemble, instance, anonymous, questionnaire, carlton, ongpin, donor, failed, bank-led, libyan, crude., tripoli, inequality, covert, discretion, leon, febre, cordero, dignity, maintain., patricio, quevedo, staple, pariba, pre-finance, plight, 18-month, oil-financing, orginal, re-establishment, mid-east, renegotiate, cairo, year-old, youssri, mustapha, hosni, mubarak, salah, bassiouni, soviet-built, soviet-supplied, then-president, anwar, sadat, promised, intellectual, revolution, steering, unrealized, bonanza, simplify, legislate, mid-1984, centrally-planned, slacken, toughen, allegiance, frenzel, poeple, agreements., reluctantly, afl-cio, kirkland, president., jenkin, proponent, beset, decision-making, sovereignty, vulnerability, hut, cambridge, there., emerging., passionate, under-developed, under-employed, newfoundlander, albertan, prosperity., detial, published, trariff, ameritrust, franklin, lessening, downgrade, toned-down, r-mi., d-il., d-mo., d-ga., augusta, paolo, torino, loophole, subsidized, derivitive, eight-billion-dlr, mcdermott, mdr, sensible, subisdy, one., friends., jople, expense., disturbed, relations., aggravation, nomination, wellington, inter-agency, oil-dependency, harrington, nickle, overestimate, tantamount, syndication, osamu, oceanic, minsiter, honda, inexpensive, ingenuity, saito, lid, owen, atico, atfc, trico, tro, scurry-rainbow, strained, engere, pasta, strident, ill-advised, provocation, brinkmanship, self-centred, accommodation, tied-aid, effot, tied, intensive, 24-nation, hidden, lessor, psbr, avoidance, dual, systematic, syst, beacon, caljet, cryssen, edgington, orkin, lunday-thagard, ring-free, mock, petro-diamond, pressing, achieve., 5-6, question-and-answer, rash, quasijudicial, mechanisim, neighbor, mccain, be., mcclure, invoice, chip-maker, discouragement, 169-billion-dlr, 59-billion-dlr, matsui, novel, wanted, collaborate, bank-funded, java, wise, unsure, arifin, siregar, depreciate, inefficient, sidetrack, sepember, southerner, instil, tragedy., popularise, readjustment, negotiations., pirate, prauge, scotland, 700-acre, taupo, verging, super-computer, dawkin, bogge, protectionist., contemplative, ago., matter., baseless, saddam, hussein, over-reliance, apea, benbow, derive, oil-generated, 1992/93, undiscovered, 1980-84, non-middle, mcivor, super-giant, home-country, non-discriminatory, meare, /exxon, uncouple, uncoupling, taboo, pietsch, re-emerging, curve, accomodate, josef, koerner, ifo-institut, wan, ncso, tsomu, hata, neglect, rollback, practice., cracker, undamaged, ingolstadt, lavera, nowruz, rubble., deprive, ruler, ardeshir, month-long, lull, dresdn, bradstreet, capitalisation, donut, stifled, samaila, mamman, micro-chip, utmost, masaji, yamamoto, renege, diminishing., nipn.t, schultz, dram.o, rock-bottom, rebuttal, strange, publicize, tonka, tka, mcd, seismic, sfb, zero-point, qassem, taqi, agcny, ina, appointing, isam, abdul-rahim, al-chalaby, subhi, yassin, khadeir, abdel-jabbar, abdel-rahim, al-asadi, baath, hamza, al-zubeidi, al-zubedei, reshuffle, realisation, freedman, fumble, unionist, krapel, persuasive, jofree, exisite, adkerson, shuffle, shakeup, inoc, appointed, incompatible, cede, noncash, rotary, scale-back, overwhelm, substitution, entirely., ludicrous, immense, non-productive, rational, 'old, rrt, profit-based, deductibility, irritant, ridden, redouble, cut-rate, revitalise, barring, bitterly, negate, secondly, thirdly, collectively, davo, canada/u., concepcion, shine, quantitative, bae, 3.60/70, 3.75/85, openness, round., nt, timetable, ex-im, morton, draugen, rd.a, northermost, 240-270, 300-meter, single-leg, gravity-base, subsea, reservoir, buoy-loading, 3p, ch, nine-member, sudan, sudanese, add-need, crunch, czechoslovakia, soviet-bloc, democratic-controlled, bonker, highly-sensitive, optima, credit-card, pei-yuan, chia, mastercard, two-to-one, braddock, ones., melbourne, heavy-handed, japan/u., provident, trout, a14-8-89-3, w5m, northstar, tricentrol, vicinity, peanut, spice, tomato, puree, oil-tax, mid-continent, taxpayer., nic, scream, cerier, impediment, competiveness, doorstep, well-placed, fashionable, japan-bashing, nic-bashing, chandross, incipient, woong, chien-shien, big-ticket, balloon, wendt, overrall, koss, exorte, two-pronged, free-trade, teeth, namibia, rundown, injurious, widening, delighted, ouput, year-to-date, interest-straining, expansionist, dogmatically, baird, non-prt, annex, participator, prt-paying, kittiwake, corner, misguided, product-for-product, wrench, boomerang, andean, caf, galo, montano, parra, gil., bentsen, televise, abbey, almy, jointly-owned, deliberately, rhone-poulenc, drawback, laiohe, 140-well, 1979-81, anytime, comecon, soviet-led, non-recognition, maslen, no., zdzislaw, kuroski, questions., presented., ec-comecon, first-ever, goc, amauligak, mud, shoreline, barite, naturally, akzo-dupont, breaking, dutch-made, disputed, aramid, mnco, 20-member, thinh, channels., inducement, re-negotiating, dillard, american-caught, pollock, standby, infant, assset, comerica, s-k-i, probability, mortgage-backed, 7-3/8, amidst, dalian, txc, galaxy, fnb, frame, arbitrary, them., globalization, perspective, r.c, indexation, abdul-aziz, mana, al-oteiba, alexandria, 8-1/4, keller, government., gravity, loan-to-price, one-eighth, adjustable-rate, memotec, quarters., cnn, careful., anchorage, rospatch, cano, pessimism, naba., calender, 85-15, chase-amp, yannis, whittaker, wkr, whittak, liu, 11-1-1, fa, hwhh.hk, wonnacott, knotty, economics, univerity, coutervailing, natw, bcs.l, mdbl.l, staunchly, 8-3/4, 2004/08, 134-12/32, inexorable, delineation, newfoundland, economicly, terra-nova, hibernia, graven, flank, parex, foulke, strenuous, riase, rotberg, rah, woon, increases., pure, 5.63-65, 5.59-61, homeless, gigantic, napo, hardest-hit, pipelline, ande, brancho, corpse, bracho, lara, landslides., cayambe, editor, adjustable, dibona, unanimity, 3-mo, 6-mo, bond-equivalent, stopout, non-competitive, santana, upco, boone, heady, autobiography, sergey, frolov, amtorg, u.s.-ussr, post-detente, teach, shenzhen, strong-armed, recalcitrant, wolffe, marketeer, sneak, non-american, matt, aizawa, outfox, donovan, mmi, k.k, opens., communism, foreign-made, urgency., megabit, thorny, sia, are., stimulative, zaid, al-nahayan, nazir, viste, palestinian, 6-1/2-year-old, battlefield, 2.25p, creditanstalt-bankverein, phrase, jumardi, jukardi, hardjoko, seputro, megabank, troublesome, flagging, inflation-free, suggested., misgiving, will., libor, unacceptably, seaga, bno.to, co-head, interest-rate, ill-will, teran, tx.n, repaid, 180-day, caracas-based, rafael, velasco, point/oil, sandi, haber, sweeney, halliburton, vishnu, diversife, businesess, favorite, horde, gaspar, choosing, swarup, cabv.vi, hanne, androsch, re-confirm, disassociate, differentials., long-held, responsibly, tragic, tableland, 4-36-2-10w2, 17/64, 20/64, spacing, srb, influx, m-4, underperforme, 32nd, one-billion, near-instant, downpayment, bellwether, 10-9-7/8, significance., materialises., disquiet, politician, westminister, jordan-petrocanada, amman, nra, pciac, al-khatib, towe, 3-5, retaliation., concessions., hesitant, reasons., speaking, piracy, puchas, eia, despatch, overwhelming, democratic-sponsored, moderated, democratic-led, imec, france., advantage., jean-baptiste, doumeng, interagra, lent, propensity, regrettably, aturo, maracaibo, guayaquil, cnooc, lufeng, 13-1-1, stationery, pazzionotto, recurrent, longstanding, peterson, peckford, formula., transpire., dissociate, ability., lucky., semi, s.africa, gradin, black-ruled, front-line, anglo-dutch, p.j, hoenman, hair, decision., musk-oxen, inadquate, dispite, solv-ex, solv, up-front, mcmurray, athabasca, powerine, selm-societa, energia, priolo, 15th, 28th, 140-150, negative-netback, garrone, quirico, isab/garrone, mellili, 20-25th, siracusa, distillation, berre, l'etang, raffinage, cfr, visbreaker, bbl/day, outlook-ecopetrol, franciso, chona, samudio, arauca, narvaez, limon, hockin, clearcut, frightening, 'protectionism, balanced., assam, pre-equity, faithfully, unsellable, knock-down, legally, chronic, petrobra, suez-mediterranean, sedi, kerir, wilfred, wae, bmd, dww, soviet-w, east-west, stein, apholte, canadaina, sponsorship, receivables, calmness, reigning, minsitry, colon, bywater, lightweights., forego, antidumping, industory, closed-minister, quota., flashpoint, early., provincially, axworthy, harrassment, bumble, whatever., ming-yi, zhao, ziyang, samsung, mob.n, cmte, committess, tic, idly, studied., sector-specific, kid, non-canadian, morse, eali, foreign-based, liabilite, cmca, rediscount, 26-week, inseperable, re-negotiate, punte, ludolf, georg, wartenberg, cooling, watchfulness, moneyline, d-tex, hundre, weston, bkb, month-end, avy, 6-5/8, debt-burdened, prior-year, mariano, washington-based, mcc, al-qaba, rosemary, mcfadden, stave, u.s.-china, figure., alone., cobanco, cbco, bfd, larsen, blender, e.b.i, esquire, ee, obod, clri, cinram, o'malley, hnh, limp, hail, saviour, pace., 45-50, 30-40, fgrp, phi, all-star, novebmer, bdm, mrdn, coleco, clo, copany, clc, cabbage, handel, dahlberg, dahl, idbx, armr, readdress, yergin, cera, mizrahi, bpd., sprigg, bijan, moussavar-rahmani, torchmark, tmk, debenure, techamerica, tch, ka-shing, gsw, lana, mccall, mayf, alatenn, atng, munsingwear, mun, gti, famous, fam, authorizerd, shrortly, likeli, cct, clever, april., moves., mid-1960, 3.7495/98, 3.7500/03, khalifa, al-thani, one-twelfth, rationalise, shoulder, responsibilite, circumstance., over-producing, tanurah, ju'aymah, two-fold, jubail, ntt, ckgh.hk, 11-21, wako, regulation-free, ingvar, calrsson, carlsson, irritate, sub-cabinet, gamut, stop-over, end-week, frustrated., free-wheeling, tight-fisted, culprit, peeve, adverserial, well-thought-out, m.p, organiaation, chao-ming, export-earner, hkeh.hk, cavendish, non-electricity, reute, sdc, cronus, buildings., tue, porx, multi-step, restructurine, hsa, whittar, dofascoxinc, bertram-trojan, investcorp, benne, marrel, juster, daewoo, wimi, strob, strb, brenco, bren, mf, skii, kapok, kpk, humanistic, 15-18, k-tron, ktii, pdo, frm, duro-test, dur, internchange, isbj, 8-1/3, nesp, phcc, mcry, benguet, i.m., imsi, muo, jcb, payble, harley-davidson, hdi, cvgi, thunander, thdr, minneosta, dpcz, sigi, ziering, annal, ziere, immunological, dunkin, dunk, cccr, off-hour, debut, mckiernan, capozza, efp, trading., up-right, upri, self-confidence, post-war, crossborder, population., imposing, albertson, intec, intk, hydron, hyd, syntech, interenational, syne, cour, ltlp, wht, reit, raut, realmerica, raco, muncipal, mfm, pittway, pry, petrolite, plit, kapsis, kaya, erdem, seabe, inactive, telecredit, tcrd, lasr, life-health, pofit, shr/avg, kenca, bkne, whipple, comalco, cmac., goldendale, chip-export, usefulness, grey-market, fison, fisn.l, 24.3p, 3.95p, 3.34p, horticulture, tito, ayal, ayala, nueva, teapa, salina, lazaro, stcl.l, 15.9p, 4.5p, impute, bougainville, buva., iron-ore, argyle, unrealised, trans-shippe, communism., anti-communist, centralled, lever, ashton-tate, 25p, 575p, transponder, equitorial, inabiliuty, agreed-upon, oblitation, cross-default, earth, conteol, under-secretary, eishiro, sub-cabinet-level, antagonise, condemnation, weill, 30-123, administration., iif, horst, schulmann, orgnaization, levelling, finance., vak, zentralsparkasse, kommerzialbank, wien, hellmuth, klauh, genossenschaftliche, zentralbank, pale, oesterreichischen, sparkassen, girv.vi, haumer, erste, spar-casse-bank, mntl, bank-wilmington, no-fee, boatman, venezula, 1987-89, minneaplois, competitive., cardholder, royal/bank, tcf, ionterest, 5-7/8, upward., bank-houston, bacp, ncf, fannie, fnm, crowd, squaring, 30-273, 30-89, 274-294, 90-100, 295-344, 101-181, 345-360, 182-195, 196-274, 275-295, 296-360, 15-78, 15-81, 79-85, 82-88, 89-360, 89-174, 175-180, 181-360\n"
     ]
    }
   ],
   "source": [
    "print(\", \".join(vocabulary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see how many times article $i$ contains word $j$ using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "i, j = 40, 2\n",
    "print(data[i,j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see which class the $i$th article belongs to using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(labels[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For instance, by running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Occurrences: 0\n",
      "Class: earn\n",
      "Word: lead\n"
     ]
    }
   ],
   "source": [
    "print(\"Occurrences:\", data[109,10])\n",
    "print(\"Class:\", class_names[labels[0]])\n",
    "print(\"Word:\", vocabulary[66])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-7-3dad177b4b8a>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-7-3dad177b4b8a>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    you can see that the 11th word appears twice in the first document, the first document belongs to the class \"earn\", and the 11th word is \"shareholder\".\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "you can see that the 11th word appears twice in the first document, the first document belongs to the class \"earn\", and the 11th word is \"shareholder\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function randomly selects a subset of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_indices(labels, *num_per_class):\n",
    "    \"\"\"\n",
    "    Returns randomly selected indices. It will return the specified number of indices for each class.\n",
    "    \"\"\"\n",
    "    indices = []\n",
    "    for cls, num in enumerate(num_per_class):\n",
    "        cls_indices = np.where(labels == cls)[0]\n",
    "        indices.extend(np.random.choice(cls_indices, size=num, replace=False))\n",
    "    return np.array(indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For instance, to get one sample from the first class, two from the second, three from the third, and four from the fourth, you can run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returned indices: [ 51 378 244 444 414 474 725 702 682 677]\n",
      "Samples:   (0, 6148)\t2\n",
      "  (0, 4794)\t2\n",
      "  (0, 1338)\t1\n",
      "  (0, 1280)\t2\n",
      "  (0, 1097)\t1\n",
      "  (0, 1041)\t3\n",
      "  (0, 814)\t1\n",
      "  (0, 205)\t2\n",
      "  (0, 184)\t1\n",
      "  (0, 171)\t1\n",
      "  (0, 75)\t1\n",
      "  (0, 73)\t2\n",
      "  (0, 33)\t1\n",
      "  (0, 30)\t1\n",
      "  (0, 23)\t1\n",
      "  (0, 15)\t1\n",
      "  (0, 14)\t1\n",
      "  (0, 13)\t1\n",
      "  (0, 5)\t1\n",
      "  (1, 5667)\t1\n",
      "  (1, 4809)\t1\n",
      "  (1, 4510)\t1\n",
      "  (1, 4258)\t1\n",
      "  (1, 2373)\t1\n",
      "  (1, 2369)\t1\n",
      "  :\t:\n",
      "  (8, 25)\t1\n",
      "  (8, 13)\t1\n",
      "  (8, 5)\t2\n",
      "  (9, 3115)\t1\n",
      "  (9, 3033)\t1\n",
      "  (9, 2154)\t1\n",
      "  (9, 1821)\t1\n",
      "  (9, 1717)\t1\n",
      "  (9, 1697)\t2\n",
      "  (9, 1183)\t2\n",
      "  (9, 1092)\t2\n",
      "  (9, 984)\t2\n",
      "  (9, 978)\t1\n",
      "  (9, 676)\t1\n",
      "  (9, 668)\t1\n",
      "  (9, 641)\t2\n",
      "  (9, 623)\t1\n",
      "  (9, 409)\t1\n",
      "  (9, 332)\t2\n",
      "  (9, 290)\t2\n",
      "  (9, 221)\t1\n",
      "  (9, 215)\t1\n",
      "  (9, 13)\t1\n",
      "  (9, 12)\t1\n",
      "  (9, 5)\t1\n",
      "Corresponding classes: [0 1 1 2 2 2 3 3 3 3]\n"
     ]
    }
   ],
   "source": [
    "indices = sample_indices(labels, 1, 2, 3, 4)\n",
    "print(\"Returned indices:\", indices)\n",
    "print(\"Samples:\", data[indices])\n",
    "print(\"Corresponding classes:\", labels[indices])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. k-NN implementation\n",
    "\n",
    "Now, you will need to implement a k-NN classifier by filling the code below.\n",
    "This function should support two types of distance measures: Euclidean distance and cosine distance.\n",
    "It should take a set of training samples, a user-specified neighour number, a distance option, and features of a set of testing samples as the input.\n",
    "It should return the predicted classes for the input set of testing samples.\n",
    "\n",
    "In order to complete this function, you will need the `sklearn.metrics.pairwise_distances` function which can handle sparse matrices, below imported as `cdist` to follow SciPy conventions (not to be confused with the `pdist` function).\n",
    "You should also research NumPy functions relating to sorting.\n",
    "\n",
    "**Your implementation must NOT make use of Python loops over individual samples**.\n",
    "You should use functions that operate on whole matrices, as this will be much faster than looping in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "from sklearn.metrics import pairwise_distances as cdist\n",
    "\n",
    "def knn_classify(test_samples, training_data, training_labels, metric=\"euclidean\", k=1):\n",
    "    \"\"\"\n",
    "    Performs k-nearest neighbour classification on the provided samples,\n",
    "    given training data and the corresponding labels.\n",
    "    \n",
    "    test_samples: An m x d matrix of m samples to classify, each with d features.\n",
    "    training_data: An n x d matrix consisting of n training samples, each with d features.\n",
    "    training_labels: A vector of size n, where training_labels[i] is the label of training_data[i].\n",
    "    metric: The metric to use for calculating distances between samples.\n",
    "    k: The number of nearest neighbours to use for classification.\n",
    "    \n",
    "    Returns: A vector of size m, where out[i] is the predicted class of test_samples[i].\n",
    "    \n",
    "       \n",
    "    # Return the most frequent class on each row.\n",
    "    # Note: Ensure that the returned vector does not contain any empty dimensions.\n",
    "    # You may find the squeeze method useful here.\n",
    "    #  return \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # Calculate an m x n distance matrix.\n",
    "    pairwise_distance = cdist(test_samples, training_data, metric)\n",
    "\n",
    "    \n",
    "    # Find the k nearest neighbours of each samples as an m x k matrix of indices.\n",
    "    nearest_neighbours = np.argsort(pairwise_distance, axis=1)[:,:k]\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    # Look up the classes corresponding to each index.\n",
    "    nearest_labels = training_labels[nearest_neighbours]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "    outputArray = stats.mode(nearest_labels, axis=1).mode\n",
    "\n",
    "    return np.squeeze(outputArray)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Experiments\n",
    "\n",
    "Use your k-NN function to perform the following experiments.\n",
    "\n",
    "### Experiment 1\n",
    "\n",
    "Randomly select 80 articles per class for training, and use the remaining articles for testing.\n",
    "Select an appropriate neighbour number.\n",
    "Train your k-NN classifier using the Euclidean distance and test it.\n",
    "Repeat this process 20 times (trials).\n",
    "Calculate the mean and standard deviation of the testing accuracies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NPSUM METHOD : Accuracy of K-NN was found at: 86.54166666666667\n",
      "NPSUM METHOD : STD of K-NN was found at: 0.021684688018148757\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ncorrectCount = 0\\ntotalCount = 0\\n\\n\\n\\nfor i in range (len(result)):\\n    if result[i] == labels[testing_samples[i]]:\\n        correctCount += 1\\n        totalCount+= 1\\n    else:\\n        print(\"ERROR FINDER: CLASS\" + str(result[i]) + \" was found INCORRECTLY as CLASS[\" + str(labels[testing_samples[i]]) +\"]\")\\n        totalCount+= 1\\n        \\nprint(\"ERROR FINDER: Total Samples checked = \" + str(totalCount))\\nprint(\"ERROR FINDER: Correct Samples checked = \" + str(correctCount))\\nincorrectCount = (totalCount - correctCount)\\nprint(\"ERROR FINDER: Incorrect Samples checked = \" + str(totalCount - correctCount))\\naccuracy = ((correctCount/totalCount) * 100)\\nprint(\"ERROR FINDER: Accuracy of K-NN was found at: \" + str(accuracy))\\n\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 3\n",
    "metric=\"euclidean\"\n",
    "\n",
    "allsamples = (sample_indices(labels, 200, 200, 200, 200))\n",
    "training_samples = (sample_indices(labels, 80, 80, 80, 80))\n",
    "testing_samples = np.setdiff1d(allsamples, training_samples)\n",
    "\n",
    "\n",
    "\n",
    "result = (knn_classify(data[testing_samples], data[training_samples], labels[training_samples], metric, k))\n",
    "arrayMeans = []\n",
    "for i in range (20):\n",
    "    allsamples = (sample_indices(labels, 200, 200, 200, 200))\n",
    "    training_samples = (sample_indices(labels, 80, 80, 80, 80))\n",
    "    testing_samples = np.setdiff1d(allsamples, training_samples)\n",
    "    result = (knn_classify(data[testing_samples], data[training_samples], labels[training_samples], metric, k))\n",
    "    acc = np.sum(result == labels[testing_samples]) / len(result)\n",
    "    arrayMeans.append(acc)\n",
    "\n",
    "print(\"NPSUM METHOD : Accuracy of K-NN was found at: \" + str(np.mean(arrayMeans) * 100))\n",
    "print(\"NPSUM METHOD : STD of K-NN was found at: \" + str(np.std(arrayMeans)))\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "correctCount = 0\n",
    "totalCount = 0\n",
    "\n",
    "\n",
    "\n",
    "for i in range (len(result)):\n",
    "    if result[i] == labels[testing_samples[i]]:\n",
    "        correctCount += 1\n",
    "        totalCount+= 1\n",
    "    else:\n",
    "        print(\"ERROR FINDER: CLASS\" + str(result[i]) + \" was found INCORRECTLY as CLASS[\" + str(labels[testing_samples[i]]) +\"]\")\n",
    "        totalCount+= 1\n",
    "        \n",
    "print(\"ERROR FINDER: Total Samples checked = \" + str(totalCount))\n",
    "print(\"ERROR FINDER: Correct Samples checked = \" + str(correctCount))\n",
    "incorrectCount = (totalCount - correctCount)\n",
    "print(\"ERROR FINDER: Incorrect Samples checked = \" + str(totalCount - correctCount))\n",
    "accuracy = ((correctCount/totalCount) * 100)\n",
    "print(\"ERROR FINDER: Accuracy of K-NN was found at: \" + str(accuracy))\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the same neighbour number, but use the cosine distance instead of the Euclidean distance.\n",
    "Repeat the same experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NPSUM METHOD : Accuracy of K-NN was found at: 96.01041666666667\n",
      "NPSUM METHOD : STD of K-NN was found at: 0.009822093682385416\n"
     ]
    }
   ],
   "source": [
    "k = 3\n",
    "metric=\"cosine\"\n",
    "\n",
    "allsamples = (sample_indices(labels, 200, 200, 200, 200))\n",
    "training_samples = (sample_indices(labels, 80, 80, 80, 80))\n",
    "testing_samples = np.setdiff1d(allsamples, training_samples)\n",
    "\n",
    "\n",
    "\n",
    "result = (knn_classify(data[testing_samples], data[training_samples], labels[training_samples], metric, k))\n",
    "arrayMeans = []\n",
    "for i in range (20):\n",
    "    allsamples = (sample_indices(labels, 200, 200, 200, 200))\n",
    "    training_samples = (sample_indices(labels, 80, 80, 80, 80))\n",
    "    testing_samples = np.setdiff1d(allsamples, training_samples)\n",
    "    result = (knn_classify(data[testing_samples], data[training_samples], labels[training_samples], metric, k))\n",
    "    acc = np.sum(result == labels[testing_samples]) / len(result)\n",
    "    arrayMeans.append(acc)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "print(\"NPSUM METHOD : Accuracy of K-NN was found at: \" + str(np.mean(arrayMeans) * 100))\n",
    "print(\"NPSUM METHOD : STD of K-NN was found at: \" + str(np.std(arrayMeans)))\n",
    "\n",
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which distance measure gives better performance?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Cosine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 2\n",
    "\n",
    "Using the distance measure that you found performs better, repeat the same experiment, varying the neighbour number $k$ from 1 to 50.\n",
    "This time, record the average training errors and standard deviation over 20 trials, for different values of $k$.\n",
    "Do the same for testing errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Produce an error bar plot showing the training accuracy for each $k$ here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K Value: 1 | Training Accuracy: 1.0| Standard Deviations: 0.0\n",
      "K Value: 2 | Training Accuracy: 0.9829687500000001| Standard Deviations: 0.007873201679590077\n",
      "K Value: 3 | Training Accuracy: 0.9821875| Standard Deviations: 0.006782042004440853\n",
      "K Value: 4 | Training Accuracy: 0.97890625| Standard Deviations: 0.006240226733661207\n",
      "K Value: 5 | Training Accuracy: 0.9768749999999999| Standard Deviations: 0.008580956386091229\n",
      "K Value: 6 | Training Accuracy: 0.97234375| Standard Deviations: 0.008284197588632235\n",
      "K Value: 7 | Training Accuracy: 0.97046875| Standard Deviations: 0.0077481726676358964\n",
      "K Value: 8 | Training Accuracy: 0.9692187500000001| Standard Deviations: 0.0076721773107443205\n",
      "K Value: 9 | Training Accuracy: 0.9682812500000001| Standard Deviations: 0.006348828016846886\n",
      "K Value: 10 | Training Accuracy: 0.9709375| Standard Deviations: 0.00791186806323262\n",
      "K Value: 11 | Training Accuracy: 0.9624999999999998| Standard Deviations: 0.009217425752345382\n",
      "K Value: 12 | Training Accuracy: 0.9643749999999999| Standard Deviations: 0.00902470567387104\n",
      "K Value: 13 | Training Accuracy: 0.9634374999999998| Standard Deviations: 0.008094896154367887\n",
      "K Value: 14 | Training Accuracy: 0.9625| Standard Deviations: 0.00872765002735558\n",
      "K Value: 15 | Training Accuracy: 0.9614062499999999| Standard Deviations: 0.011192343574403877\n",
      "K Value: 16 | Training Accuracy: 0.9607812500000001| Standard Deviations: 0.008295977470286436\n",
      "K Value: 17 | Training Accuracy: 0.9617187499999998| Standard Deviations: 0.007253433992771991\n",
      "K Value: 18 | Training Accuracy: 0.9631250000000001| Standard Deviations: 0.0063737743919909775\n",
      "K Value: 19 | Training Accuracy: 0.9615625000000003| Standard Deviations: 0.009432117670491617\n",
      "K Value: 20 | Training Accuracy: 0.9581250000000001| Standard Deviations: 0.011667596689121559\n",
      "K Value: 21 | Training Accuracy: 0.9578125| Standard Deviations: 0.0069526860816521725\n",
      "K Value: 22 | Training Accuracy: 0.95796875| Standard Deviations: 0.010052353191541765\n",
      "K Value: 23 | Training Accuracy: 0.9579687499999998| Standard Deviations: 0.009136283691277324\n",
      "K Value: 24 | Training Accuracy: 0.95921875| Standard Deviations: 0.009503031999709347\n",
      "K Value: 25 | Training Accuracy: 0.9571875000000001| Standard Deviations: 0.008273876434296078\n",
      "K Value: 26 | Training Accuracy: 0.9575000000000002| Standard Deviations: 0.007806247497997993\n",
      "K Value: 27 | Training Accuracy: 0.9515624999999999| Standard Deviations: 0.01010201867202788\n",
      "K Value: 28 | Training Accuracy: 0.9534374999999999| Standard Deviations: 0.011175971713904796\n",
      "K Value: 29 | Training Accuracy: 0.9510937500000001| Standard Deviations: 0.008963630943289658\n",
      "K Value: 30 | Training Accuracy: 0.9496875000000001| Standard Deviations: 0.01099982244174876\n",
      "K Value: 31 | Training Accuracy: 0.9529687499999999| Standard Deviations: 0.009399707026684393\n",
      "K Value: 32 | Training Accuracy: 0.9532812500000001| Standard Deviations: 0.009605245555814811\n",
      "K Value: 33 | Training Accuracy: 0.9409374999999999| Standard Deviations: 0.00837942979861996\n",
      "K Value: 34 | Training Accuracy: 0.9526562499999999| Standard Deviations: 0.0076082680149624216\n",
      "K Value: 35 | Training Accuracy: 0.9454687500000001| Standard Deviations: 0.008754184267394646\n",
      "K Value: 36 | Training Accuracy: 0.94453125| Standard Deviations: 0.011218488854899303\n",
      "K Value: 37 | Training Accuracy: 0.94625| Standard Deviations: 0.010852347096365829\n",
      "K Value: 38 | Training Accuracy: 0.9403124999999999| Standard Deviations: 0.009926487608917865\n",
      "K Value: 39 | Training Accuracy: 0.94140625| Standard Deviations: 0.008551030182820081\n",
      "K Value: 40 | Training Accuracy: 0.946875| Standard Deviations: 0.012884705080055188\n",
      "K Value: 41 | Training Accuracy: 0.9418749999999999| Standard Deviations: 0.006281172263200563\n",
      "K Value: 42 | Training Accuracy: 0.9384375| Standard Deviations: 0.010274551389233506\n",
      "K Value: 43 | Training Accuracy: 0.94046875| Standard Deviations: 0.009756558291093231\n",
      "K Value: 44 | Training Accuracy: 0.9354687500000001| Standard Deviations: 0.011016456085670201\n",
      "K Value: 45 | Training Accuracy: 0.93875| Standard Deviations: 0.006945659615904036\n",
      "K Value: 46 | Training Accuracy: 0.9309375| Standard Deviations: 0.010453580427298579\n",
      "K Value: 47 | Training Accuracy: 0.9376562500000002| Standard Deviations: 0.012000773087076522\n",
      "K Value: 48 | Training Accuracy: 0.9353124999999999| Standard Deviations: 0.009985340817919035\n",
      "K Value: 49 | Training Accuracy: 0.9376562500000001| Standard Deviations: 0.008057108177721085\n",
      "K Value: 50 | Training Accuracy: 0.93515625| Standard Deviations: 0.0098759394331628\n",
      "K Value: 1 | Testing Accuracy: 0.9633333333333335| Standard Deviations: 0.007750448015724277\n",
      "K Value: 2 | Testing Accuracy: 0.9542708333333332| Standard Deviations: 0.007110090394408985\n",
      "K Value: 3 | Testing Accuracy: 0.9603125| Standard Deviations: 0.008319650224685601\n",
      "K Value: 4 | Testing Accuracy: 0.9604166666666666| Standard Deviations: 0.008960755486502743\n",
      "K Value: 5 | Testing Accuracy: 0.9585416666666667| Standard Deviations: 0.009030715334038852\n",
      "K Value: 6 | Testing Accuracy: 0.9607291666666665| Standard Deviations: 0.010443195385566201\n",
      "K Value: 7 | Testing Accuracy: 0.9588541666666666| Standard Deviations: 0.008637043724883864\n",
      "K Value: 8 | Testing Accuracy: 0.9608333333333332| Standard Deviations: 0.006705615391429624\n",
      "K Value: 9 | Testing Accuracy: 0.9614583333333332| Standard Deviations: 0.009375\n",
      "K Value: 10 | Testing Accuracy: 0.9547916666666667| Standard Deviations: 0.009639779417716073\n",
      "K Value: 11 | Testing Accuracy: 0.9549999999999998| Standard Deviations: 0.009161930594706689\n",
      "K Value: 12 | Testing Accuracy: 0.9634375000000001| Standard Deviations: 0.007863720979211347\n",
      "K Value: 13 | Testing Accuracy: 0.9551041666666666| Standard Deviations: 0.004817637949936349\n",
      "K Value: 14 | Testing Accuracy: 0.9560416666666667| Standard Deviations: 0.0067796417063637595\n",
      "K Value: 15 | Testing Accuracy: 0.9546875| Standard Deviations: 0.007449919602474488\n",
      "K Value: 16 | Testing Accuracy: 0.9556250000000001| Standard Deviations: 0.0062534712582515365\n",
      "K Value: 17 | Testing Accuracy: 0.9579166666666664| Standard Deviations: 0.006305310812675663\n",
      "K Value: 18 | Testing Accuracy: 0.9540624999999998| Standard Deviations: 0.006019175088830717\n",
      "K Value: 19 | Testing Accuracy: 0.9554166666666666| Standard Deviations: 0.009624007885375922\n",
      "K Value: 20 | Testing Accuracy: 0.9553125000000001| Standard Deviations: 0.007017927192792295\n",
      "K Value: 21 | Testing Accuracy: 0.9529166666666666| Standard Deviations: 0.009372684899335008\n",
      "K Value: 22 | Testing Accuracy: 0.9527083333333332| Standard Deviations: 0.009662265521087702\n",
      "K Value: 23 | Testing Accuracy: 0.9471875000000001| Standard Deviations: 0.008314431688669756\n",
      "K Value: 24 | Testing Accuracy: 0.95375| Standard Deviations: 0.009873329675893999\n",
      "K Value: 25 | Testing Accuracy: 0.9511458333333331| Standard Deviations: 0.011775441575820228\n",
      "K Value: 26 | Testing Accuracy: 0.9472916666666669| Standard Deviations: 0.010460325175527679\n",
      "K Value: 27 | Testing Accuracy: 0.9492708333333333| Standard Deviations: 0.009866183652310108\n",
      "K Value: 28 | Testing Accuracy: 0.9496874999999999| Standard Deviations: 0.010989953587759648\n",
      "K Value: 29 | Testing Accuracy: 0.9466666666666667| Standard Deviations: 0.008799463367476213\n",
      "K Value: 30 | Testing Accuracy: 0.9494791666666667| Standard Deviations: 0.008981921464499934\n",
      "K Value: 31 | Testing Accuracy: 0.9442708333333332| Standard Deviations: 0.011389471106391784\n",
      "K Value: 32 | Testing Accuracy: 0.9470833333333333| Standard Deviations: 0.007580585582775107\n",
      "K Value: 33 | Testing Accuracy: 0.9438541666666668| Standard Deviations: 0.012816733717856677\n",
      "K Value: 34 | Testing Accuracy: 0.9419791666666667| Standard Deviations: 0.011548414844326768\n",
      "K Value: 35 | Testing Accuracy: 0.9446874999999997| Standard Deviations: 0.01245608605706909\n",
      "K Value: 36 | Testing Accuracy: 0.9372916666666669| Standard Deviations: 0.009476304512953452\n",
      "K Value: 37 | Testing Accuracy: 0.9419791666666667| Standard Deviations: 0.009530538452492805\n",
      "K Value: 38 | Testing Accuracy: 0.9386458333333332| Standard Deviations: 0.010934523404489707\n",
      "K Value: 39 | Testing Accuracy: 0.9377083333333334| Standard Deviations: 0.00883637919185352\n",
      "K Value: 40 | Testing Accuracy: 0.9388541666666669| Standard Deviations: 0.009733314604719412\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K Value: 41 | Testing Accuracy: 0.9356250000000002| Standard Deviations: 0.010843344733060912\n",
      "K Value: 42 | Testing Accuracy: 0.9371875| Standard Deviations: 0.009063697238924556\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-04eea2be443a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mtraining_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msample_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m80\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m80\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m80\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m80\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mtesting_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdiff1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mallsamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mknn_classify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtesting_samples\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtraining_samples\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtraining_samples\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \"\"\"\n",
      "\u001b[0;32m<ipython-input-16-124f93189353>\u001b[0m in \u001b[0;36mknn_classify\u001b[0;34m(test_samples, training_data, training_labels, metric, k)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;31m# Calculate an m x n distance matrix.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mpairwise_distance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcdist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mpairwise_distances\u001b[0;34m(X, Y, metric, n_jobs, **kwds)\u001b[0m\n\u001b[1;32m   1400\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcdist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1402\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_parallel_pairwise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36m_parallel_pairwise\u001b[0;34m(X, Y, func, n_jobs, **kwds)\u001b[0m\n\u001b[1;32m   1067\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1068\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0meffective_n_jobs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1069\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1070\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1071\u001b[0m     \u001b[0;31m# TODO: in some cases, backend='threading' may be appropriate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mcosine_distances\u001b[0;34m(X, Y)\u001b[0m\n\u001b[1;32m    550\u001b[0m     \"\"\"\n\u001b[1;32m    551\u001b[0m     \u001b[0;31m# 1.0 - cosine_similarity(X, Y) without copy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m     \u001b[0mS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m     \u001b[0mS\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m     \u001b[0mS\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mcosine_similarity\u001b[0;34m(X, Y, dense_output)\u001b[0m\n\u001b[1;32m    905\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m     K = safe_sparse_dot(X_normalized, Y_normalized.T,\n\u001b[0;32m--> 907\u001b[0;31m                         dense_output=dense_output)\n\u001b[0m\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/sklearn/utils/extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    166\u001b[0m     \"\"\"\n\u001b[1;32m    167\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdense_output\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"toarray\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36m__mul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dimension mismatch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 479\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mul_sparse_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m         \u001b[0;31m# If it's a list or whatever, treat it like a matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/scipy/sparse/compressed.py\u001b[0m in \u001b[0;36m_mul_sparse_matrix\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    510\u001b[0m            \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0midx_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m            \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 512\u001b[0;31m            indptr, indices, data)\n\u001b[0m\u001b[1;32m    513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "k = 3\n",
    "metric=\"cosine\"\n",
    "\n",
    "\n",
    "\n",
    "trainingErrors = []\n",
    "arrayAccuracy = []\n",
    "acArray = []\n",
    "stdArray = []\n",
    "meanKarray = []\n",
    "\n",
    "\n",
    "\n",
    "for ix in range (50):\n",
    "    k = ix+1\n",
    "\n",
    "    \n",
    "    for i in range (20):\n",
    "\n",
    "        allsamples = (sample_indices(labels, 200, 200, 200, 200))\n",
    "        training_samples = (sample_indices(labels, 80, 80, 80, 80))\n",
    "        testing_samples = np.setdiff1d(allsamples, training_samples)\n",
    "        result = (knn_classify(data[training_samples], data[training_samples], labels[training_samples], metric, k))\n",
    "        \n",
    "        \n",
    "        acc = np.sum(result == labels[training_samples]) / len(result)\n",
    "        acArray.append(acc)\n",
    "        \n",
    "        \"\"\"\n",
    "        # Initialise Variables\n",
    "        errorCount = 0\n",
    "        correctCount = 0\n",
    "        totalCount = 0\n",
    "\n",
    "         # Change occurs here for testing samples to compare\n",
    "        for i in range (len(result)):\n",
    "            if result[i] == labels[training_samples[i]]:\n",
    "                correctCount += 1\n",
    "                totalCount+= 1\n",
    "            else:\n",
    "                errorCount += 1\n",
    "                totalCount+= 1\n",
    "                \n",
    "\n",
    "                \n",
    "        trainingErrors.append(errorCount)\n",
    "        trainingErrors = []\n",
    "        \n",
    "        accuracy = ((correctCount/result.size))\n",
    "        acArray.append(accuracy)\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "    print(\"K Value: \" + str(k) + \" | Training Accuracy: \" + str(np.mean(acArray)) + \"| Standard Deviations: \" + str(np.std(acArray)))\n",
    "    meanKarray.append(np.mean(acArray))\n",
    "    stdArray.append(np.std(acArray))\n",
    "    acArray = []\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "trainingErrors = []\n",
    "arrayAccuracy = []\n",
    "acArray2 = []\n",
    "meanKarray2 = []\n",
    "stdArray2 = []\n",
    "        \n",
    "for ix in range (50):\n",
    "    k = ix+1\n",
    "   \n",
    "\n",
    "    \n",
    "    \n",
    "    for i in range (20):\n",
    "\n",
    "        allsamples = (sample_indices(labels, 200, 200, 200, 200))\n",
    "        training_samples = (sample_indices(labels, 80, 80, 80, 80))\n",
    "        testing_samples = np.setdiff1d(allsamples, training_samples)\n",
    "        result = (knn_classify(data[testing_samples], data[training_samples], labels[training_samples], metric, k))\n",
    "        \n",
    "        \"\"\"\n",
    "        # Initialise Variables\n",
    "        errorCount = 0\n",
    "        correctCount = 0\n",
    "        totalCount = 0\n",
    "\n",
    "         # Change occurs here for testing samples to compare\n",
    "        for i in range (len(result)):\n",
    "            if result[i] == labels[testing_samples[i]]:\n",
    "                correctCount += 1\n",
    "                totalCount+= 1\n",
    "            else:\n",
    "                errorCount += 1\n",
    "                totalCount+= 1\n",
    "                \n",
    "\n",
    "                \n",
    "        trainingErrors.append(errorCount)\n",
    "        trainingErrors = []\n",
    "        accuracy = ((correctCount/result.size))\n",
    "        \n",
    "        acArray2.append(acc)\n",
    "        \"\"\"\n",
    "        \n",
    "        acc = np.sum(result == labels[testing_samples]) / len(result)\n",
    "        acArray2.append(acc)\n",
    "        \n",
    "        \n",
    "    print(\"K Value: \" + str(k) + \" | Testing Accuracy: \" + str(np.mean(acArray2)) + \"| Standard Deviations: \" + str(np.std(acArray2)))\n",
    "    meanKarray2.append(np.mean(acArray2))\n",
    "    stdArray2.append(np.std(acArray2))\n",
    "    acArray2 = []\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(1, 51)\n",
    "y = meanKarray\n",
    "plt.xlabel('K parameter')\n",
    "plt.ylabel('Accuracy ')\n",
    "plt.errorbar(x, y, yerr=stdArray, ecolor='r')\n",
    "\n",
    "plt.title('A plot of K versus Accuracy for training')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Produce your testing error bar plot here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(1, 51)\n",
    "y = meanKarray2\n",
    "plt.xlabel('K parameter')\n",
    "plt.ylabel('Accruacy %')\n",
    "plt.errorbar(x, y, yerr=stdArray2, ecolor='r')\n",
    "plt.title('A plot of K versus Accuracy for testing Accuracy')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remember that all graphs should have axis labels and a title.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, answer a few questions according to what you have observed.\n",
    "\n",
    "Q1. What is the training accuracy obtained when $k=1$? Explain it."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "100% as there is no influence of neighbour numbers except the sample itself which is identical to the train/testing sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2. Do the testing and training accuracies differ, and why?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Testing Accuracies Are genreally lower. This is because the data has more chance of being dissimilar and hard to classify. Where as training errors come from the algorithim/influence from K-NN (k) classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3. How do the accuracies change as $k$ gets bigger, and why?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The number of influencing Neighbours mean increase the over all P(Error) as more neighbours = more cases for erorr."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 3\n",
    "\n",
    "Compare three 5-NN classifiers using cosine distance.\n",
    "First, randomly select 100 articles per class and keep these as your testing samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "allsamples = (sample_indices(labels, 200, 200, 200, 200))\n",
    "test_samples = (sample_indices(labels, 100, 100, 100, 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then do the following:\n",
    "\n",
    "(1) Train the first classifier using all the remaining articles.\n",
    "Compute the confusion matrix for the 4 classes using the testing samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 99   5]\n",
      " [  1 295]]\n",
      "[[ 99   1]\n",
      " [  1 299]]\n",
      "[[ 96   2]\n",
      " [  4 298]]\n",
      "[[ 97   1]\n",
      " [  3 299]]\n"
     ]
    }
   ],
   "source": [
    "train_samples = np.setdiff1d(allsamples, training_samples)\n",
    "firstClassifier = (knn_classify(data[test_samples], data[train_samples], labels[train_samples], \"cosine\", 5))\n",
    "\n",
    "# Predict that the first 100 samples(class 0) Will be equal \n",
    "def truePositive(matrix1):\n",
    "    return np.sum(matrix1)\n",
    "\n",
    "# Predict False Negatives\n",
    "def falseNegative(sampleperclassnumber, matrix1):\n",
    "    return sampleperclassnumber - truePositive(matrix1)\n",
    "\n",
    "def falsePositive(matrix,testmatrix, classnumber,boundv):\n",
    "    return (np.bincount(matrix[boundv:] == classnumber)[1])\n",
    "\n",
    "def trueNegative(matrix,testmatrix,classnumber,boundv):\n",
    "    return np.bincount(matrix[boundv:] != classnumber)[1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Predict true positives for first 100 samples\n",
    "class0Matrix = (firstClassifier[:100] == labels[test_samples][:100])\n",
    "tp0 = truePositive(class0Matrix)\n",
    "\n",
    "\n",
    "\n",
    "# Predict false Negative for first 100 samples\n",
    "fn0 = falseNegative(100, class0Matrix)\n",
    "\n",
    "boundv = 100\n",
    "# Predict false Positive for 0\n",
    "fp0 = falsePositive(firstClassifier,test_samples, 0,boundv)\n",
    "    \n",
    "        \n",
    "# Predict True Negative for 0\n",
    "tn0 = trueNegative(firstClassifier,test_samples, 0,boundv)\n",
    "\n",
    "confusionMatrixClass0 = np.array([[tp0,fp0],[fn0,tn0]])\n",
    "print(confusionMatrixClass0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def otherfalsePositive(matrix,testmatrix,classnumber, bound1,bound2,bound3,bound4):\n",
    "    matrixa = matrix[bound1:bound2]\n",
    "    matrixb = matrix[bound3:bound4]\n",
    "    newarray = np.concatenate((matrixa,matrixb), axis=0)\n",
    "    return (np.bincount(newarray == classnumber)[1])\n",
    "\n",
    "def othertrueNegative(matrix,testmatrix,classnumber,bound1,bound2,bound3,bound4):\n",
    "    matrixa = matrix[bound1:bound2]\n",
    "    matrixb = matrix[bound3:bound4]\n",
    "    newarray = np.concatenate((matrixa,matrixb), axis=None)\n",
    "    return (np.bincount(newarray != classnumber)[1])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Predict true positives for first 100 samples\n",
    "class1Matrix = (firstClassifier[100:200] == labels[test_samples][100:200])\n",
    "tp1 = truePositive(class1Matrix)\n",
    "\n",
    "\n",
    "\n",
    "# Predict false Negative for first 100 samples\n",
    "fn1 = falseNegative(100, class1Matrix)\n",
    "\n",
    "bound1 = 0\n",
    "bound2 = 100\n",
    "bound3 = 200\n",
    "bound4 = 400\n",
    "# Predict false Positive for 1\n",
    "fp1 = otherfalsePositive(firstClassifier,test_samples, 1, bound1, bound2, bound3, bound4)\n",
    "    \n",
    "            \n",
    "# Predict True Negative for 1\n",
    "tn1 = othertrueNegative(firstClassifier,test_samples, 1, bound1, bound2, bound3, bound4)\n",
    "\n",
    "confusionMatrixClass1 = np.array([[tp1,fp1],[fn1,tn1]])\n",
    "print(confusionMatrixClass1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Predict true positives for first 100 samples\n",
    "class2Matrix = (firstClassifier[200:300] == labels[test_samples][200:300])\n",
    "tp2 = truePositive(class2Matrix)\n",
    "\n",
    "\n",
    "\n",
    "# Predict false Negative for first 100 samples\n",
    "fn2 = falseNegative(100, class2Matrix)\n",
    "\n",
    "bound1 = 0\n",
    "bound2 = 200\n",
    "bound3 = 300\n",
    "bound4 = 400\n",
    "# Predict false Positive for 1\n",
    "fp2 = otherfalsePositive(firstClassifier,test_samples, 2, bound1, bound2, bound3, bound4)\n",
    "    \n",
    "            \n",
    "# Predict True Negative for 1\n",
    "tn2 = othertrueNegative(firstClassifier,test_samples, 2, bound1, bound2, bound3, bound4)\n",
    "\n",
    "confusionMatrixClass2 = np.array([[tp2,fp2],[fn2,tn2]])\n",
    "print(confusionMatrixClass2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def extrafalsePositive(matrix,testmatrix,classnumber, bound1,bound2):\n",
    "    matrixa = matrix[bound1:bound2]\n",
    "    return (np.bincount(matrixa == classnumber)[1])\n",
    "\n",
    "def extratrueNegative(matrix,testmatrix,classnumber,bound1,bound2):\n",
    "    matrixa = matrix[bound1:bound2]\n",
    "    return (np.bincount(matrixa != classnumber)[1])\n",
    "\n",
    "\n",
    "\n",
    "# Predict true positives for first 100 samples\n",
    "class3Matrix = (firstClassifier[300:400] == labels[test_samples][300:400])\n",
    "tp3 = truePositive(class3Matrix)\n",
    "\n",
    "\n",
    "\n",
    "# Predict false Negative for first 100 samples\n",
    "fn3 = falseNegative(100, class3Matrix)\n",
    "\n",
    "bound1 = 0\n",
    "bound2 = 300\n",
    "# Predict false Positive for 1\n",
    "fp3 = extrafalsePositive(firstClassifier,test_samples, 3, bound1, bound2)\n",
    "    \n",
    "            \n",
    "# Predict True Negative for 1\n",
    "tn3 = extratrueNegative(firstClassifier,test_samples, 3, bound1, bound2)\n",
    "\n",
    "confusionMatrixClass3 = np.array([[tp3,fp3],[fn3,tn3]])\n",
    "print(confusionMatrixClass3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) Randomly remove 95 training articles from class 2.\n",
    "Train the second classifier using the reduced training samples.\n",
    "Compute the confusion matrix for the 4 classes using the testing samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 98  15]\n",
      " [  2 285]]\n",
      "[[ 85   2]\n",
      " [ 15 298]]\n",
      "[[ 98  12]\n",
      " [  2 288]]\n",
      "[[ 89   1]\n",
      " [ 11 299]]\n"
     ]
    }
   ],
   "source": [
    "random_train_samples = np.random.choice(train_samples[100:200],5)\n",
    "new_train_samples = np.concatenate((train_samples[0:100],random_train_samples, train_samples[200:400]), axis=None)\n",
    "\n",
    "newClassifier = (knn_classify(data[test_samples], data[new_train_samples], labels[new_train_samples], \"cosine\", 5))\n",
    "\n",
    "# Predict that the first 100 samples(class 0) Will be equal \n",
    "def truePositive(matrix1):\n",
    "    return np.sum(matrix1)\n",
    "\n",
    "# Predict False Negatives\n",
    "def falseNegative(sampleperclassnumber, matrix1):\n",
    "    return sampleperclassnumber - truePositive(matrix1)\n",
    "\n",
    "def falsePositive(matrix,testmatrix, classnumber,boundv):\n",
    "    return (np.bincount(matrix[boundv:] == classnumber)[1])\n",
    "\n",
    "def trueNegative(matrix,testmatrix,classnumber,boundv):\n",
    "    return np.bincount(matrix[boundv:] != classnumber)[1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Predict true positives for first 100 samples\n",
    "class0Matrix = (newClassifier[:100] == labels[test_samples][:100])\n",
    "tp0 = truePositive(class0Matrix)\n",
    "\n",
    "\n",
    "\n",
    "# Predict false Negative for first 100 samples\n",
    "fn0 = falseNegative(100, class0Matrix)\n",
    "\n",
    "boundv = 100\n",
    "# Predict false Positive for 0\n",
    "fp0 = falsePositive(newClassifier,test_samples, 0,boundv)\n",
    "    \n",
    "        \n",
    "# Predict True Negative for 0\n",
    "tn0 = trueNegative(newClassifier,test_samples, 0,boundv)\n",
    "\n",
    "confusionMatrixClass0 = np.array([[tp0,fp0],[fn0,tn0]])\n",
    "print(confusionMatrixClass0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def otherfalsePositive(matrix,testmatrix,classnumber, bound1,bound2,bound3,bound4):\n",
    "    matrixa = matrix[bound1:bound2]\n",
    "    matrixb = matrix[bound3:bound4]\n",
    "    newarray = np.concatenate((matrixa,matrixb), axis=None)\n",
    "    return (np.bincount(newarray == classnumber)[1])\n",
    "\n",
    "def othertrueNegative(matrix,testmatrix,classnumber,bound1,bound2,bound3,bound4):\n",
    "    matrixa = matrix[bound1:bound2]\n",
    "    matrixb = matrix[bound3:bound4]\n",
    "    newarray = np.concatenate((matrixa,matrixb), axis=None)\n",
    "    return (np.bincount(newarray != classnumber)[1])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Predict true positives for first 100 samples\n",
    "class1Matrix = (newClassifier[100:200] == labels[test_samples][100:200])\n",
    "tp1 = truePositive(class1Matrix)\n",
    "\n",
    "\n",
    "\n",
    "# Predict false Negative for first 100 samples\n",
    "fn1 = falseNegative(100, class1Matrix)\n",
    "\n",
    "bound1 = 0\n",
    "bound2 = 100\n",
    "bound3 = 200\n",
    "bound4 = 400\n",
    "# Predict false Positive for 1\n",
    "fp1 = otherfalsePositive(newClassifier,test_samples, 1, bound1, bound2, bound3, bound4)\n",
    "    \n",
    "            \n",
    "# Predict True Negative for 1\n",
    "tn1 = othertrueNegative(newClassifier,test_samples, 1, bound1, bound2, bound3, bound4)\n",
    "\n",
    "confusionMatrixClass1 = np.array([[tp1,fp1],[fn1,tn1]])\n",
    "print(confusionMatrixClass1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Predict true positives for first 100 samples\n",
    "class2Matrix = (newClassifier[200:300] == labels[test_samples][200:300])\n",
    "tp2 = truePositive(class2Matrix)\n",
    "\n",
    "\n",
    "\n",
    "# Predict false Negative for first 100 samples\n",
    "fn2 = falseNegative(100, class2Matrix)\n",
    "\n",
    "bound1 = 0\n",
    "bound2 = 200\n",
    "bound3 = 300\n",
    "bound4 = 400\n",
    "# Predict false Positive for 1\n",
    "fp2 = otherfalsePositive(newClassifier,test_samples, 2, bound1, bound2, bound3, bound4)\n",
    "    \n",
    "            \n",
    "# Predict True Negative for 1\n",
    "tn2 = othertrueNegative(newClassifier,test_samples, 2, bound1, bound2, bound3, bound4)\n",
    "\n",
    "confusionMatrixClass2 = np.array([[tp2,fp2],[fn2,tn2]])\n",
    "print(confusionMatrixClass2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def extrafalsePositive(matrix,testmatrix,classnumber, bound1,bound2):\n",
    "    matrixa = matrix[bound1:bound2]\n",
    "    return (np.bincount(matrixa == classnumber)[1])\n",
    "\n",
    "def extratrueNegative(matrix,testmatrix,classnumber,bound1,bound2):\n",
    "    matrixa = matrix[bound1:bound2]\n",
    "    return (np.bincount(matrixa != classnumber)[1])\n",
    "\n",
    "\n",
    "\n",
    "# Predict true positives for first 100 samples\n",
    "class3Matrix = (newClassifier[300:400] == labels[test_samples][300:400])\n",
    "tp3 = truePositive(class3Matrix)\n",
    "\n",
    "\n",
    "\n",
    "# Predict false Negative for first 100 samples\n",
    "fn3 = falseNegative(100, class3Matrix)\n",
    "\n",
    "bound1 = 0\n",
    "bound2 = 300\n",
    "# Predict false Positive for 1\n",
    "fp3 = extrafalsePositive(newClassifier,test_samples, 3, bound1, bound2)\n",
    "    \n",
    "            \n",
    "# Predict True Negative for 1\n",
    "tn3 = extratrueNegative(newClassifier,test_samples, 3, bound1, bound2)\n",
    "\n",
    "confusionMatrixClass3 = np.array([[tp3,fp3],[fn3,tn3]])\n",
    "print(confusionMatrixClass3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3) Redo (2), but randomly remove 95 training articles from *all* the classes.\n",
    "Train the third classifier using the new training data.\n",
    "Compute the confusion matrix for the 4 classes using the testing samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  3 105]\n",
      " [ 12 290]]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-180-6f9aba7cc2f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0mbound4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;31m# Predict false Positive for 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m \u001b[0mfp1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0motherfalsePositive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthirdClassifier\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbound1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbound2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbound3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbound4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-180-6f9aba7cc2f7>\u001b[0m in \u001b[0;36motherfalsePositive\u001b[0;34m(matrix, testmatrix, classnumber, bound1, bound2, bound3, bound4)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mmatrixb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbound3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbound4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mnewarray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatrixa\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmatrixb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbincount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewarray\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mclassnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mothertrueNegative\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtestmatrix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclassnumber\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbound1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbound2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbound3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbound4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for axis 0 with size 1"
     ]
    }
   ],
   "source": [
    "random_train_samples0 = np.random.choice(train_samples[:100],5)\n",
    "random_train_samples1 = np.random.choice(train_samples[100:200],5)\n",
    "random_train_samples2 = np.random.choice(train_samples[200:300],5)\n",
    "random_train_samples3 = np.random.choice(train_samples[300:400],5)\n",
    "new_train_samples = np.concatenate((random_train_samples0,random_train_samples1, random_train_samples2, random_train_samples3), axis=None)\n",
    "\n",
    "thirdClassifier = (knn_classify(data[test_samples], data[new_train_samples], labels[new_train_samples], \"cosine\", 5))\n",
    "\n",
    "# Predict that the first 100 samples(class 0) Will be equal \n",
    "def truePositive(matrix1):\n",
    "    return np.sum(matrix1)\n",
    "\n",
    "# Predict False Negatives\n",
    "def falseNegative(sampleperclassnumber, matrix1):\n",
    "    return sampleperclassnumber - truePositive(matrix1)\n",
    "\n",
    "def falsePositive(matrix,testmatrix, classnumber,boundv):\n",
    "    return (np.bincount(matrix[boundv:] == classnumber)[1])\n",
    "\n",
    "def trueNegative(matrix,testmatrix,classnumber,boundv):\n",
    "    return np.bincount(matrix[boundv:] != classnumber)[1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Predict true positives for first 100 samples\n",
    "class0Matrix = (thirdClassifier[:5] == labels[test_samples][:5])\n",
    "tp0 = truePositive(class0Matrix)\n",
    "\n",
    "\n",
    "\n",
    "# Predict false Negative for first 100 samples\n",
    "fn0 = falseNegative(15, class0Matrix)\n",
    "\n",
    "boundv = 5\n",
    "# Predict false Positive for 0\n",
    "fp0 = falsePositive(thirdClassifier,test_samples, 0,boundv)\n",
    "    \n",
    "        \n",
    "# Predict True Negative for 0\n",
    "tn0 = trueNegative(thirdClassifier,test_samples, 0,boundv)\n",
    "\n",
    "confusionMatrixClass0 = np.array([[tp0,fp0],[fn0,tn0]])\n",
    "print(confusionMatrixClass0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def otherfalsePositive(matrix,testmatrix,classnumber, bound1,bound2,bound3,bound4):\n",
    "    matrixa = matrix[bound1:bound2]\n",
    "    matrixb = matrix[bound3:bound4]\n",
    "    newarray = np.concatenate((matrixa,matrixb), axis=None)\n",
    "    return (np.bincount(newarray == classnumber)[1])\n",
    "\n",
    "def othertrueNegative(matrix,testmatrix,classnumber,bound1,bound2,bound3,bound4):\n",
    "    matrixa = matrix[bound1:bound2]\n",
    "    matrixb = matrix[bound3:bound4]\n",
    "    newarray = np.concatenate((matrixa,matrixb), axis=None)\n",
    "    return (np.bincount(newarray != classnumber)[1])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Predict true positives for first 100 samples\n",
    "class1Matrix = (thirdClassifier[5:10] == labels[test_samples][5:10])\n",
    "tp1 = truePositive(class1Matrix)\n",
    "\n",
    "\n",
    "\n",
    "# Predict false Negative for first 100 samples\n",
    "fn1 = falseNegative(5, class1Matrix)\n",
    "\n",
    "bound1 = 0\n",
    "bound2 = 5\n",
    "bound3 = 10\n",
    "bound4 = 20\n",
    "# Predict false Positive for 1\n",
    "fp1 = otherfalsePositive(thirdClassifier,test_samples, 1, bound1, bound2, bound3, bound4)\n",
    "    \n",
    "            \n",
    "# Predict True Negative for 1\n",
    "tn1 = othertrueNegative(thirdClassifier,test_samples, 1, bound1, bound2, bound3, bound4)\n",
    "\n",
    "confusionMatrixClass1 = np.array([[tp1,fp1],[fn1,tn1]])\n",
    "print(confusionMatrixClass1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Predict true positives for first 100 samples\n",
    "class2Matrix = (thirdClassifier[10:15] == labels[test_samples][10:15])\n",
    "tp2 = truePositive(class2Matrix)\n",
    "\n",
    "\n",
    "\n",
    "# Predict false Negative for first 100 samples\n",
    "fn2 = falseNegative(5, class2Matrix)\n",
    "\n",
    "bound1 = 0\n",
    "bound2 = 10\n",
    "bound3 = 15\n",
    "bound4 = 20\n",
    "# Predict false Positive for 1\n",
    "fp2 = otherfalsePositive(thirdClassifier,test_samples, 2, bound1, bound2, bound3, bound4)\n",
    "    \n",
    "            \n",
    "# Predict True Negative for 1\n",
    "tn2 = othertrueNegative(thirdClassifier,test_samples, 2, bound1, bound2, bound3, bound4)\n",
    "\n",
    "confusionMatrixClass2 = np.array([[tp2,fp2],[fn2,tn2]])\n",
    "print(confusionMatrixClass2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def extrafalsePositive(matrix,testmatrix,classnumber, bound1,bound2):\n",
    "    matrixa = matrix[bound1:bound2]\n",
    "    return (np.bincount(matrixa == classnumber)[1])\n",
    "\n",
    "def extratrueNegative(matrix,testmatrix,classnumber,bound1,bound2):\n",
    "    matrixa = matrix[bound1:bound2]\n",
    "    check = (np.bincount(matrixa != classnumber)[1])\n",
    "    print(check)\n",
    "    return (np.bincount(matrixa != classnumber)[1])\n",
    "\n",
    "\n",
    "\n",
    "# Predict true positives for first 100 samples\n",
    "class3Matrix = (thirdClassifier[15:20] == labels[test_samples][15:20])\n",
    "tp3 = truePositive(class3Matrix)\n",
    "\n",
    "\n",
    "\n",
    "# Predict false Negative for first 100 samples\n",
    "fn3 = falseNegative(5, class3Matrix)\n",
    "\n",
    "bound1 = 0\n",
    "bound2 = 15\n",
    "# Predict false Positive for 1\n",
    "fp3 = extrafalsePositive(thirdClassifier,test_samples, 3, bound1, bound2)\n",
    "    \n",
    "            \n",
    "# Predict True Negative for 1\n",
    "tn3 = extratrueNegative(thirdClassifier,test_samples, 3, bound1, bound2)\n",
    "\n",
    "confusionMatrixClass3 = np.array([[tp3,fp3],[fn3,tn3]])\n",
    "print(confusionMatrixClass3)\n",
    "print(\"check\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat the whole thing a few times.\n",
    "Which of the three classifiers performs the worst?\n",
    "Try to analyse why this might be."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Deliverables and Marking\n",
    "\n",
    "By the deadline, you should submit one single Jupyter file using GitLab.\n",
    "Please find the coursework submission instruction from the following link:\n",
    "https://wiki.cs.manchester.ac.uk/index.php/UGHandbook19:Coursework\n",
    "\n",
    "This exercise is worth 15 marks — marks will be allocated roughly on the basis of:\n",
    "* rigorous experimentation,\n",
    "* knowledge displayed when talking to the TA,\n",
    "* problem solving skill,\n",
    "* self-learning ability,\n",
    "* how informative and well presented your graphs are,\n",
    "* language and ease of reading.\n",
    "\n",
    "You must be able to explain any code you've written in order to get full marks. During the marking session we will ask you to run all cells in your Jupyter file, so ensure that the file is runnable using the \"Restart Kernel and Run All Cells\" menu option.\n",
    "\n",
    "The lab is marked out of 15:\n",
    "\n",
    "|                          |         |\n",
    "|:------------------------ |--------:|\n",
    "| k-NN Implementation      | 3 marks |\n",
    "| Experiment 1             | 4 marks |\n",
    "| Experiment 2             | 4 marks |\n",
    "| Experiment 3             | 4 marks |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
